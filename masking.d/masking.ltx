\documentclass[draft,12pt]{amsart}

\usepackage[final]{listings}
\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}
\usepackage{arydshln}

\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{ragged2e}
\usepackage{url}
\usepackage[final]{hyperref}
\usepackage{placeins}
\usepackage{mfirstuc}
\usepackage{ifdraft}
\usepackage[obeyDraft]{todonotes}
\usepackage{datetime2}
\ifdraft{
    \usepackage{draftwatermark}
}{}

% Fix conflict between todonotes and amsart packages
% See http://ctan.math.washington.edu/tex-archive/macros/latex/contrib/todonotes/todonotes.pdf,
% p. 10.
\makeatletter
\providecommand\@dotsep{5}
\def\listtodoname{List of TODOs}
\def\listoftodos{\@starttoc{tdo}\listtodoname}
\makeatother

\makeatletter
\renewcommand{\listofalgorithms}{\@starttoc{loa}{List of algorithms}}
\let\l@algorithm=\l@figure
\makeatother

% Re hbox's, see
% https://tex.stackexchange.com/questions/241343/what-is-the-meaning-of-fussy-sloppy-emergencystretch-tolerance-hbadness
\raggedbottom

% Replaced by todonotes package
% \newcommand{\todo}[1]{\par{\large\bf Todo: #1}\par}

\newcommand{\mymathop}[1]{\mathop{\texttt{#1}}}
\newcommand{\mymathbin}[1]{\mathbin{\texttt{#1}}}

% For a type name, when it occurs in text
\newcommand{\type}[1]{\ensuremath{\texttt{#1}}}

\newcommand{\mult}{\mathbin{\ast}}
\newcommand{\dfn}[1]{{\bf #1}}
\newcommand{\sep}{\,\mid\,}
\newcommand{\mydot}{\raisebox{.05em}{$\,\bullet\,$}}
\newcommand{\cat}{\,.\,}
\newcommand{\size}[1]{\ensuremath{\left | {#1} \right |}}
\newcommand{\Vsize}[1]{\ensuremath{\size{\var{#1}}}}
\newcommand{\bigsize}[1]{\ensuremath{\bigl| {#1} \bigr|}}
\newcommand{\order}[1]{\ensuremath{{\mathcal O}(#1)}\xspace}
\newcommand{\Oc}{\order{1}}
\newcommand{\On}{\order{\var{n}}}
\newcommand{\inference}[2]{\genfrac{}{}{1pt}{}{#1}{#2}}

\newcommand{\lastix}[1]{\ensuremath{\##1}}
\newcommand{\Vlastix}[1]{\ensuremath{\lastix{\V{#1}}}}
\newcommand{\VlastElement}[1]{\Velement{#1}{\Vlastix{#1}}}
\newcommand{\element}[2]{\ensuremath{\mathop{#1}
    \mathopen{}\left[#2\right]\mathclose{}}}
\newcommand{\Velement}[2]{\ensuremath{\mathop{\V{#1}}
    \mathopen{}\left[#2\right]\mathclose{}}}
\newcommand{\VVelement}[2]{\ensuremath{\mathop{\V{#1}}
    \mathopen{}\left[ \V{#2}
    \right]\mathclose{} }}

\newcommand{\tuple}[1]{\ensuremath{\left\langle #1 \right\rangle}}

\newcommand{\mcolon}{\mathrel:}
\newcommand{\mcoloncolon}{\mathrel{\vcenter{\hbox{$::$}}}}

\newcommand{\suchthat}{\mcoloncolon}
\newcommand{\quantify}[3]{% quantifier, binding, predicate
    \ensuremath{\mathrel{#1}#2 \; \suchthat \; #3}%
}

% I use hyphens in variable names,
% so I need to ensure that subtraction is
% clearly distinguished by the typography
\newcommand{\subtract}{\,-\,}

\newcommand{\var}[1]{\ensuremath{\texttt{#1}}}
\newcommand{\V}[1]{\ensuremath{\texttt{\mbox{#1}}}}

\newcommand{\cfg}{CFG}

\newcommand{\de}{\mathrel{::=}}
\newcommand{\derives}{\Rightarrow}
\newcommand{\destar}
    {\mathrel{\mbox{$\:\stackrel{\!{\ast}}{\Rightarrow\!}\:$}}}
\newcommand{\deplus}
    {\mathrel{\mbox{$\:\stackrel{\!{+}}{\Rightarrow\!}\:$}}}
\newcommand{\derivg}[1]{\mathrel{\mbox{$\:\Rightarrow\:$}}}
\newcommand{\derivrg}[2]{\mathrel{\mbox{$\:\stackrel{\!{#1}}%
        {\Rightarrow\!}\:$}}}

% For the type subscript for powersets
\newcommand{\setOf}[1]{{{#1}^{\mbox{\normalsize $\ast$}}}}

\newcommand{\set}[1]{{\left\lbrace #1 \right\rbrace} }
\newcommand{\bigset}[1]{{\bigl\lbrace #1 \bigr\rbrace} }
\newcommand{\Bigset}[1]{{\Bigl\lbrace #1 \Bigr\rbrace} }

% use internal counter of algorithmicx
\newcommand{\algnested}{ %
  \makeatletter\ALG@nested\makeatother %
}

\newcommand{\algstrut}{\rule{0pt}{.85\baselineskip}}

\newcommand{\myparbox}[2][\algparwidth]{%
  \parbox[t]{#1}{%
  % \linespread{1.15}\selectfont
  \ignorespaces#2\par%
  }%
}

\newcommand{\parcomment}[2]{\hspace{\dimexpr \algorithmicindent * #1}$\triangleright$ #2}

% \newcommand{\rawparcomment}[2][\algparwidth]{%
  % \myparbox[#1]{#2}%
% }
% \newcommand{\parcomment}[2][\algparwidth]{%
  % \myparbox[#1]{$\triangleright$ #2}%
% }
% \newcommand{\parcomment}[1]{\hspace{\dimexpr \algorithmicindent - \labelwidth }$\triangleright$
  % \protect\parbox[t]{\dimexpr \textwidth - (\algorithmicindent - \labelwidth)}{#1}%
% }

% I want to use 'call' outside of pseudocode
\newcommand\call[2]{\textproc{#1}\ifthenelse{\equal{#2}{}}{}{(#2)}}%

\newcommand{\mname}[1]{\mbox{\sf #1}}
% [O]perator [A]pplication
\newcommand{\Oname}[1]{\mname{#1}}
% The \mathopen{} and \mathclose{} eliminate unwanted extra space
\newcommand{\OA}[2]{\ensuremath{%
    \mathop{\Oname{#1}}\mathopen{}\left(#2\right)\mathclose{}%
}}
\newcommand{\VOA}[2]{\OA{#1}{\V{#2}}}
% [F]unction [A]pplication, replaces \myfn
\newcommand{\smallrawfn}[2]{\ensuremath{\mathop{#1}(#2)}}
% The \mathopen{} and \mathclose{} eliminate unwanted extra space
\newcommand{\rawfn}[2]{\ensuremath{\mathop{#1}\mathopen{}\left(#2\right)\mathclose{}}}
\newcommand{\Fname}[1]{\V{#1}}
\newcommand{\FA}[2]{\ensuremath{\rawfn{\mathop{\Fname{#1}}}{#2}}}
\newcommand{\VFA}[2]{\FA{#1}{\V{#2}}}

\hyphenation{oper-and oper-ands}
\hyphenation{look-ahead}
\hyphenation{memo-ization}

% I like to silence underfull hbox messages.
% This is syntactic sugar for doing that.
\newenvironment{MYsloppy}[1][3em]{\par\tolerance9999 \emergencystretch#1\relax}{\par}
% This form allows the resetting of hbadness, which may be necessary to
% shut up an "underfull" warning.
\newenvironment{MYsloppyB}[2]{\par\tolerance9999 \emergencystretch#1 \hbadness#2\relax}{\par}
% This form is for a trick:  Tolerances are evaluated line by line, so a tolerance
% less than 9999 may produce a better looking paragraph and reduce the "badness".
\newenvironment{MYsloppyC}[3]{\par\tolerance#3 \emergencystretch#1 \hbadness#2\relax}{\par}

\title
  [Masking Thoughts]
  {Thoughts on optimizing the computation of masks}

\author{Jeffrey Kegler}
\ifdraft{
    % legacy draftwatermark options -- update?
    \SetWatermarkLightness{0}
    \SetWatermarkText{DRAFT \DTMnow{} DRAFT}
    \SetWatermarkAngle{0}
    % \SetWatermarkScale{1}
    % \SetWatermarkHorCenter{1.5in}
    \SetWatermarkVerCenter{.5in}
}{}
\ifdraft{ \thanks{DRAFT as of \DTMnow} }{}
\date{\DTMnow.}

\begin{document}

\maketitle
\tableofcontents

\section{About this document}
\label{sec:about-me}

This document outlines a method for optimizing mask computation in
Guidance.
It assumes some familiarity with the code in
llguidance\cite{llguidance}.

\section{Conventions}
\begin{itemize}
\item ``Iff'' (or ``iff'') abbreviates
	``if and only if''.
\item Ranges are inclusive start,
	exclusive end so that, for example,
		\begin{gather*}
			\element{(\texttt{"abcd"})}{0,2} = \texttt{"ab"} \text{, and} \\
			\element{(\texttt{"abcd"})}{2,3} = \texttt{"c"}.
		\end{gather*}
\end{itemize}

\section{The Basic Idea}

The basic idea behind the suggestions in this document is more
aggressive use of the Ruby Slippers.
The Ruby Slippers is
a parsing technique discovered independently by Jeffrey Kegler%
\cite{Kegler2011a}\cite{Kegler2011b}\cite{Kegler2023}
and
Michal Moskal\cite{llguidance}.
It takes advantage of the ability of certain variants of the Earley
parser to tell the application
exactly which terminals will be acceptable at
any point in the parse.
This allows the application to change the lexeme stream to match
the parser's expectations.
The application could, for example, invent a lexeme on the fly
to accomodate the parser.\footnote{%
    The name ``Ruby Slippers'' comes from a incident in the movie
    {\it Wizard of Oz}.  In it Dorothy, the protagonist, is trying
    to return to her home in Kansas.  After many adventures she
    discovers that a pair of ruby slippers, which she has been
    wearing throughout the movie, grant her this ability.
    She has merely to click her heels and wish.}

The Ruby Slippers are already in use
in llguidance.
An \url{allowed\_lexemes} vector is computed,
and applied at certain points.

Looking ahead
in this document, we are going to claim
that the Ruby Slippers can be used earlier and more extensively,
that much of the work of applying the
Ruby Slippers can be done when the grammar is compiled, rather
than ``online'', as the parse progresses,
and that other work, not efficient to do at pre-computation,
can be done ``lazily'' and cached.\footnote{%
        For discussion of the trade-offs between precomputation and
        lazy computation with caching, see Section \ref{sec:lazy}.
        }
It is hoped that this will allow considerable savings in time.

\FloatBarrier

\section{The structure of the byte stream}
\label{sec:byte-stream}

\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
	\multicolumn{2}{c}{TB} &
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\rule{30pt}{0pt} &
	\multicolumn{2}{c|}{ALA} &
\multicolumn{2}{p{72pt}}{\centering Current} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
	\multicolumn{2}{p{72pt}|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{p{30pt}|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{p{30pt}|}{\rule{30pt}{0pt}} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-5}
	\multicolumn{2}{|p{72pt}|}{\centering \hyphenpenalty=10000 accepted lexeme} &
	% 30pt * 5 + 12pt * 4 = 198pt
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt} working lexeme}
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-6}
\rule{30pt}{0pt} &
	\multicolumn{2}{|p{72pt}|}{\centering committed token} &
	% 30pt * 3 + 12pt * 2 = 114pt
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt} working token} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-7}
	\multicolumn{4}{|p{156pt}|}{\centering seen input} &
	\multicolumn{3}{|p{114pt}}{\centering unseen input} \\
\cline{1-4}\cdashline{5-7}
\end{tabular}
\par\vspace{12pt}
\noindent
``Current'' is Current location in the byte stream. \\
``ALA'' is the Allowed Lexeme Anchor. \\
``TB'' is the Toktrie Base. \\
\vspace{6pt}
\caption{Input structure}
\label{fig:input-1}
\end{figure}

\FloatBarrier

As a reminder, in performing the mask computation we simulate byte streams
which are divided into tokens,
and check them for acceptability against a parser which divides that same byte stream into lexemes.
From the parser
we are given a list of acceptable lexemes.
We want to use this to determine which tokens are acceptable.
Once we know which tokens are acceptable,
we can produce a token mask,
which in turn will allow us to sample a token.

To determine the acceptable tokens, we travserse a trie of the tokens,
implicitly checking the tokens against all possible byte streams.
Every node in the trie traversal implies a single byte stream,
which may be seen as structured according to the scheme in
Figure \ref{fig:input-1}
on page \pageref{fig:input-1}.

In our byte stream diagrams, we have identified
\begin{itemize}
	\item the most recently accepted lexeme,
	\item the most recently committed token,
	\item a lexeme in progress (aka the ''working lexeme''), and
	\item a token in progress (aka the ''working token'').
\end{itemize}
In the byte stream, we note three locations of special significance:
\begin{itemize}
	\item The current location, which is the byte location location
		implied by our token trie traversal.  We abbreviate this
		as \V{Current}.
	\item The ``toktrie base'', that is, the start location for our toktrie
		traversal, which we abbreviate \V{TB}.
		\V{TB} is at the end of the last committed token,
		if it exists, and at the start of parsing otherwise.
	\item The location for which we calculated the allowed lexemes,
		that is, the ``allowed lexeme location''.
		We abbreviate this as \V{ALA}.
		\V{ALA} is at the end of the last accepted lexeme,
		if it exists, and at the start of parsing otherwise.
\end{itemize}

It is always the case the current location is at or after TB:
\begin{equation}
\label{eq:invariant-1}
\V{TB} \le \V{Current}.
\end{equation}
It is also always the case the current location
is at or after the ALA:
\begin{equation}
\label{eq:invariant}
\V{ALA} \le \V{Current}.
\end{equation}

Our byte stream diagrams will make some assumptions
without loss of generality.
We will assume
there is a last committed token and
a last accepted lexeme.
And, while the invariants of
equation \ref{eq:invariant-1} on page \pageref{eq:invariant-1} and
equation \ref{eq:invariant-2} on page \pageref{eq:invariant-2}
will always be obeyed,
otherwise our byte stream diagrams may make arbitrary
assumptions about the relative length of the tokens and lexemes.
For example, Figure \ref{fig:input-2}
on page \pageref{fig:input-2}
is similar to Figure \ref{fig:input-1}
on page \pageref{fig:input-1},
except that, while Figure \ref{fig:input-1} shows a working
lexeme that ends {\bf before} the working token,
Figure \ref{fig:input-1} shows a working
token that ends {\bf after} the working token.

\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
\multicolumn{2}{c}{TB} &
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\rule{30pt}{0pt} &
\multicolumn{2}{c|}{ALA} &
\multicolumn{2}{c}{Current} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\multicolumn{2}{c|}{} &
\multicolumn{1}{c|}{} &
\multicolumn{1}{c|}{} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\cline{1-4}\cdashline{5-7}
	\multicolumn{2}{|p{72pt}|}{\centering \hyphenpenalty=10000 accepted lexeme} &
	% 30pt * 5 + 12pt * 4 = 198pt
	\multicolumn{5}{|p{198pt};{2pt/2pt}}{\centering\vspace{-1pt}working lexeme} \\
\cline{1-4}\cdashline{5-7}
\rule{30pt}{0pt} &
	\multicolumn{2}{|p{72pt}|}{\centering committed token} &
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working token} &
        \rule{30pt}{0pt} \\
\cline{1-4}\cdashline{5-7}
	\multicolumn{4}{|p{156pt}|}{\centering seen input} &
	\multicolumn{3}{|p{114pt}}{\centering unseen input} \\
\cline{1-4}\cdashline{5-7}
\end{tabular}
\vspace{6pt}
\caption{Input structure with long working lexeme}
\label{fig:input-2}
\end{figure}

The \V{ALA} may occur before or after the \V{TB}.
Where
\begin{equation}
\label{eq:offset}
	\V{off} = \V{TB} \subtract \V{ALA},
\end{equation}
we call \V{off} the
{\bf lexeme offset}\label{loc:lexeme-offset}.

\section{Lexeme slices}

Lexeme slices are like string slices, and are represented similarly,
so that $\Velement{lex}{0,2}$ is a lexeme which matches the first two
characters of a string which matches \V{lex} and $\Velement{lex}{2,3}$
is a lexeme which matches the third character of a string which matches
\V{lex}.

Not all lexemes can be sliced conveniently.
When a lexeme is hard to slice,
we say that it is {\bf tough}.
We consider cases.

\subsection{Fixed strings}

Where a lexeme is a fixed string,
its slices {\bf are} string slices,
and can be easily computed.
In practice, most
lexemes are fixed strings.

\subsection{Regular expressions without Kleene stars}

When a lexeme has no Kleene star,
it is also easy to compute its slices.

\subsection{Regular expressions with Kleene stars}

Lexemes with Kleene stars can be tough,
but some are easily sliceable.
For example, if $\V{lex} = /a*/$, then
$\Velement{lex}[0,2] = /aa/$
and 
$\Velement{lex}[2,3] = /a/$.

\subsection{Other lexemes}

Lexemes can be many other things besides regular expressions,
including subgrammars.
If a lexeme indicates how it can be sliced,
then it may be sliceable,
but often such lexemes will be tough.

\section{Lexeme slices and token trie nodes}

In the context of token trie nodes,
lexeme slices anchored around the current token
trie node are of special interest.
We call these ``anchored lexeme slices''.
Anchored lexeme slices can be conveniently represented as a duple.

Recall (equation \ref{eq:lexeme-offset} on page \pageref{loc:lexeme-offset})
that we defined the lexeme offset as \V{off}
where $\V{off} = \V{TB} \subtract \V{ALA}.$
An anchored lexeme slice can be represented as
as $(\V{lex}, \V{off})$.

For convenience in defining, anchored lexeme slices
we set out some definitions.
Let \V{node} be a token trie node,
let \V{path} be the path from the trie root
to \V{node}, treated as a vector of nodes.
We represent the length of \V{path}, also
called the depth of \V{node},
as \Vsize{path}.
Abusing notation a bit, we also write
\Vsize{path} as \Vsize{node}.

If \V{off} is positive, so that $\V{TB} > \V{ALA}$,
then
\[
	(\V{lex}, \V{off}) = \Velement{lex}{(\V{TB}\subtract\V{ALA}), (\V{Curr}\subtract\V{ALA)}}.
\]

\section{Stage 1: Calculating allowed tokens}

The lexsuf vectors can be used to eliminate calls to
\url{try\_push\_byte}.
We will refer the code snippet\footnote{%
    This code snippet is similar to, and taken from,
    \url{https://github.com/microsoft/llguidance/blob/0ca091a701a50134e0503fa03c5c12b206e182a3/toktrie/src/toktree.rs\#L945}.
}
in Figure \ref{fig:try-push-byte} on page \pageref{fig:try-push-byte}.
\begin{figure}
\begin{lstlisting}
    while p < endp {
        r.pop_bytes(next_pop);
        let n = &self.nodes[p];
        let b = n.byte();
        // Click ruby slipper heels here
        if r.try_push_byte(b) {
            toks.allow_token(n.token_id().
                unwrap_or(defl_tok)
            );
            // ... stuff here ...
        } else {
            // ... other stuff here ...
        }
    }
\end{lstlisting}
\caption{Ruby Slippers Click Point%
    \label{fig:try-push-byte}%
}
\end{figure}

The test {\tt r.try\_push\_byte(b)} is true iff
the intersection of the possible lexsufs at trie node \V{n}
and the allowed lexsufs at that point in the code is non-empty.
By testing for this non-empty intersection, we hope to save most
calls to \url{try\_push\_byte}.

\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
        \multicolumn{2}{c}{ALA} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} \\
	% ===
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
        \multicolumn{2}{c|}{TB} &
        \multicolumn{2}{c}{Current} \\
	% ===
	\rule{30pt}{0pt} &
        \multicolumn{2}{c|}{} &
	\multicolumn{1}{c|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{c|}{\rule{30pt}{0pt}} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} \\
	% ===
\cline{1-5}\cdashline{6-7}
\multicolumn{4}{|c|}{accepted lexeme} &
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working lexeme} \\
\cline{1-5}\cdashline{6-7}
        \rule{30pt}{0pt} &
        \multicolumn{2}{|p{6em}|}{\centering committed token} &
        \multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working token}
        \\
	% ===
\cline{1-5}\cdashline{6-7}
\multicolumn{5}{|c|}{seen input} &
        \multicolumn{2}{|c}{unseen input} \\
\cline{1-5}\cdashline{6-7}
\end{tabular}
\vspace{6pt}
\caption{Input structure with token split between lexemes}
\label{fig:input-3}
\end{figure}

\section{Stage 2: Track EOLs}
\label{sec:stage2}

\section{Optimization}

\section{Forcing}

In this document we say we are ``lexeme forcing'' when there is only one
relevant lexeme at a location.
The optimization described here detects situations where lexemes can be
forced and handles their tokenization in the same way as it handles
the tokenization of other lexemes.

\FloatBarrier

{
\clearpage

% Ragged right, do not hyphenate.
\RaggedRight
\hyphenpenalty=10000
\exhyphenpenalty=10000

% Silence current hbox warnings, but allow them if
% badness increases further
\hbadness=2000

\begin{thebibliography}{10}

\bibitem{Kegler2011a}
\newblock{Jeffrey Kegler.}
\newblock{``What is the Marpa algorithm?''.}
\newblock{\url{https://blogs.perl.org/users/jeffrey_kegler/2011/11/what-is-the-marpa-algorithm.html}.
   Retrieved 2 Dec, 2024.}

\bibitem{Kegler2011b}
\newblock{Jeffrey Kegler.}
\newblock{``Marpa and the Ruby Slippers''.}
\newblock{\url{http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2011/11/marpa-and-the-ruby-slippers.html}.
   Retrieved 2 Dec, 2024.}

\bibitem{Kegler2023}
\newblock{Jeffrey Kegler.}
\newblock{``Marpa, A practical general parser: the recognizer''.}
\newblock{\url{https://arxiv.org/abs/1910.08129}.
   Retrieved 2 Dec, 2024.}

\bibitem{llguidance}
\newblock{llguidance.}
\newblock{"Low-level guidance parser."}
\newblock{
  \url{https://github.com/microsoft/llguidance}.
  Retrieved 2 Dec, 2024.}

\end{thebibliography}

} % RaggedRight

% \clearpage
% \phantomsection
% \listofalgorithms

\ifdraft{
    \clearpage
    \phantomsection
    \listoftodos
}{}

\end{document}
