\documentclass[draft,12pt]{amsart}

\usepackage[final]{listings}
\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}
\usepackage{arydshln}
\usepackage{multirow}
\usepackage{needspace}

\usepackage{amssymb}
\usepackage{wasysym} % Used for \Circle
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{ragged2e}
\usepackage{url}
\usepackage[final]{hyperref}
\usepackage{placeins}
\usepackage{mfirstuc}
\usepackage{ifdraft}
\usepackage[obeyDraft]{todonotes}
\usepackage{datetime2}
\ifdraft{
    \usepackage{draftwatermark}
}{}

% Fix conflict between todonotes and amsart packages
% See http://ctan.math.washington.edu/tex-archive/macros/latex/contrib/todonotes/todonotes.pdf,
% p. 10.
\makeatletter
\providecommand\@dotsep{5}
\def\listtodoname{List of TODOs}
\def\listoftodos{\@starttoc{tdo}\listtodoname}
\makeatother

\makeatletter
\renewcommand{\listofalgorithms}{\@starttoc{loa}{List of algorithms}}
\let\l@algorithm=\l@figure
\makeatother

% Re hbox's, see
% https://tex.stackexchange.com/questions/241343/what-is-the-meaning-of-fussy-sloppy-emergencystretch-tolerance-hbadness
\raggedbottom

% Replaced by todonotes package
% \newcommand{\todo}[1]{\par{\large\bf Todo: #1}\par}

\newcommand{\mymathop}[1]{\mathop{\texttt{#1}}}
\newcommand{\mymathbin}[1]{\mathbin{\texttt{#1}}}

% For a type name, when it occurs in text
\newcommand{\type}[1]{\ensuremath{\texttt{#1}}}

\newcommand{\True}{\mbox{\sf T}\xspace}
\newcommand{\False}{\mbox{\sf F}\xspace}
\newcommand{\Trueword}{\sf true}
\newcommand{\Falseword}{\sf false}
\newcommand{\Neg}{\neg}
\newcommand{\Implies}{\supset}
\newcommand{\ImpliesAlt}{\Rightarrow}
\newcommand{\NEquiv}{\not\equiv}
\newcommand{\NEquivRel}{\mathrel{\not\equiv}}

\newcommand{\qeq}{\simeq}
\newcommand{\nqeq}{\not\simeq}
\newcommand{\unicorn}{\ensuremath{\bot}\xspace}
\newcommand{\TRUE}{\ensuremath{\mathbb T}\xspace}
\newcommand{\FALSE}{\ensuremath{\mathbb F}\xspace}

\newcommand{\mult}{\mathbin{\ast}}
\newcommand{\dfn}[1]{{\bf #1}}
\newcommand{\sep}{\,\mid\,}
\newcommand{\mydot}{\raisebox{.05em}{$\,\bullet\,$}}
\newcommand{\cat}{\,.\,}
\newcommand{\size}[1]{\ensuremath{\left | {#1} \right |}}
\newcommand{\Vsize}[1]{\ensuremath{\size{\var{#1}}}}
\newcommand{\bigsize}[1]{\ensuremath{\bigl| {#1} \bigr|}}
\newcommand{\order}[1]{\ensuremath{{\mathcal O}(#1)}\xspace}
\newcommand{\Oc}{\order{1}}
\newcommand{\On}{\order{\var{n}}}
\newcommand{\inference}[2]{\genfrac{}{}{1pt}{}{#1}{#2}}

\newcommand{\lastix}[1]{\ensuremath{\##1}}
\newcommand{\Vlastix}[1]{\ensuremath{\lastix{\V{#1}}}}
\newcommand{\VlastElement}[1]{\Velement{#1}{\Vlastix{#1}}}
\newcommand{\element}[2]{\ensuremath{\mathop{#1}
    \mathopen{}\left[#2\right]\mathclose{}}}
\newcommand{\Velement}[2]{\ensuremath{\mathop{\V{#1}}
    \mathopen{}\left[#2\right]\mathclose{}}}
\newcommand{\VVelement}[2]{\ensuremath{\mathop{\V{#1}}
    \mathopen{}\left[ \V{#2}
    \right]\mathclose{} }}

\newcommand{\tuple}[1]{\ensuremath{\left\langle #1 \right\rangle}}

\newcommand{\mcolon}{\mathrel:}
\newcommand{\mcoloncolon}{\mathrel{\vcenter{\hbox{$::$}}}}

\newcommand{\suchthat}{\mcoloncolon}
\newcommand{\quantify}[3]{% quantifier, binding, predicate
    \ensuremath{\mathrel{#1}#2 \; \suchthat \; #3}%
}

% I use hyphens in variable names,
% so I need to ensure that subtraction is
% clearly distinguished by the typography
\newcommand{\subtract}{\,-\,}

\newcommand{\var}[1]{\ensuremath{\texttt{#1}}}
\newcommand{\V}[1]{\ensuremath{\texttt{\mbox{#1}}}}

\newcommand{\cfg}{CFG}

\newcommand{\de}{\mathrel{::=}}
\newcommand{\derives}{\Rightarrow}
\newcommand{\destar}
    {\mathrel{\mbox{$\:\stackrel{\!{\ast}}{\Rightarrow\!}\:$}}}
\newcommand{\deplus}
    {\mathrel{\mbox{$\:\stackrel{\!{+}}{\Rightarrow\!}\:$}}}
\newcommand{\derivg}[1]{\mathrel{\mbox{$\:\Rightarrow\:$}}}
\newcommand{\derivrg}[2]{\mathrel{\mbox{$\:\stackrel{\!{#1}}%
        {\Rightarrow\!}\:$}}}

% For the type subscript for powersets
\newcommand{\setOf}[1]{{{#1}^{\mbox{\normalsize $\ast$}}}}

\newcommand{\set}[1]{{\left\lbrace #1 \right\rbrace} }
\newcommand{\bigset}[1]{{\bigl\lbrace #1 \bigr\rbrace} }
\newcommand{\Bigset}[1]{{\Bigl\lbrace #1 \Bigr\rbrace} }

% use internal counter of algorithmicx
\newcommand{\algnested}{ %
  \makeatletter\ALG@nested\makeatother %
}

\newcommand{\algstrut}{\rule{0pt}{.85\baselineskip}}

\newcommand{\myparbox}[2][\algparwidth]{%
  \parbox[t]{#1}{%
  % \linespread{1.15}\selectfont
  \ignorespaces#2\par%
  }%
}

\newcommand{\parcomment}[2]{\hspace{\dimexpr \algorithmicindent * #1}$\triangleright$ #2}

% \newcommand{\rawparcomment}[2][\algparwidth]{%
  % \myparbox[#1]{#2}%
% }
% \newcommand{\parcomment}[2][\algparwidth]{%
  % \myparbox[#1]{$\triangleright$ #2}%
% }
% \newcommand{\parcomment}[1]{\hspace{\dimexpr \algorithmicindent - \labelwidth }$\triangleright$
  % \protect\parbox[t]{\dimexpr \textwidth - (\algorithmicindent - \labelwidth)}{#1}%
% }

% I want to use 'call' outside of pseudocode
\newcommand\call[2]{\textproc{#1}\ifthenelse{\equal{#2}{}}{}{(#2)}}%

\newcommand{\mname}[1]{\mbox{\sf #1}}
% [O]perator [A]pplication
\newcommand{\Oname}[1]{\mname{#1}}
% The \mathopen{} and \mathclose{} eliminate unwanted extra space
\newcommand{\OA}[2]{\ensuremath{%
    \mathop{\Oname{#1}}\mathopen{}\left(#2\right)\mathclose{}%
}}
\newcommand{\VOA}[2]{\OA{#1}{\V{#2}}}
% [F]unction [A]pplication, replaces \myfn
\newcommand{\smallrawfn}[2]{\ensuremath{\mathop{#1}(#2)}}
% The \mathopen{} and \mathclose{} eliminate unwanted extra space
\newcommand{\rawfn}[2]{\ensuremath{\mathop{#1}\mathopen{}\left(#2\right)\mathclose{}}}
\newcommand{\Fname}[1]{\V{#1}}
\newcommand{\FA}[2]{\ensuremath{\rawfn{\mathop{\Fname{#1}}}{#2}}}
\newcommand{\VFA}[2]{\FA{#1}{\V{#2}}}

% * Reference meta tags ("classifying prefixes") use in this document:
% * From fancyref:
% Chapter chap:
% Section sec:
% Equation eq:
% Figure fig:
% Table tab:
% Enumeration enum:
% Footnote fn:
%
% * Not in fancyref
% Definition df:
% Epigraph epi:
% Theorem th:
% Lemma lm:
% Remark rm:
% Observation obs:
% Example ex:
% Page page:

% The "page:" metatag is for labels intended as the target of
% page references.

% The auto-placement of qed's fails a lot.
% Semi-manual replacement using \qedhere often fails as well.
% I went with % 100% manual placement,
% which in fact is not any more trouble,
% and which is the only way to guarantee the QED's wind up where I
% want them.

% Try to gather all the stuff to do with theoremoids here
% Start off with theorems, then the other theoremoids,
% mostly alphabetically.

\renewcommand{\qedsymbol}{}
\newcommand{\myqed}{%
  \ifmmode\square
  \else$\square$
  \fi%
}

\newcommand{\colonpageref}[1]{%
 \ifthenelse{\equal{\pageref{#1}}{\thepage}}%
  {}{{:}\pageref*{#1}}%
}

% genref -- generic reference
\newcommand{\genref}[3][]{%
    \ifthenelse{\equal{#1}{}}{}{%
      \ifmmode \text{``#1''}%
      \else``#1'' %
      \fi%
    }%
    (\ensuremath{% To cover both cases, force math mode
        \hyperref[#2]{%
            \textrm{#3}\ref*{#2}\colonpageref{#2}%
        }%
    })%
}

\theoremstyle{definition}

% theoremoids: Th

\newtheorem{theorem}{Theorem}
\newcommand{\Thref}[2][]{%
    \genref[#1]{th:#2}{Th}%
}
% some day delete \longThref
\newcommand{\longThref}[2]{%
  \ifmmode \text{``#1''\Thref{#2}}%
  \else``#1'' \Thref{#2}%
  \fi%
}
% "full" ref -- always includes page
\newcommand{\ThFref}[1]{(\textrm{Th}\ref{#1}:\pageref{#1})}
\newcommand{\thEnd}{\Circle}

% theoremoids: Df

\newtheorem{definition}[theorem]{Definition}
\newcommand{\Dfref}[2][]{%
    \genref[#1]{df:#2}{Df}%
}
\newcommand{\dfEnd}{\Circle}

% theoremoids: Ex

\newtheorem{example}[theorem]{Example}
\newcommand{\Exref}[1]{\genref{ex:#1}{Ex}}
\newcommand{\exEnd}{\Circle}

\newcommand{\Eqref}[1]{\genref{eq:#1}{Eq}}
\newcommand{\Figref}[1]{\genref{fig:#1}{Fig}}

% theoremoids: Ob

\newtheorem{observation}[theorem]{Observation}
\newcommand{\Obref}[1]{\genref{obs:#1}{Ob}}
\newcommand{\obEnd}{\Circle}

% theoremoids: Rm

\newtheorem{remark}[theorem]{Remark}
\newcommand{\Rmref}[2][]{\genref[#1]{rm:#2}{Rm}}
\newcommand{\rmEnd}{\Circle}

% local theoremoids: Lm

\newtheorem{lemma}[theorem]{Lemma}
\newcommand{\Lmref}[2][]{\genref[#1]{lm:#2}{Lm}}
% some day delete \longLmref
\newcommand{\longLmref}[2]{%
  \ifmmode \text{``#1''\Lmref{#2}}%
  \else``#1'' \Lmref{#2}%
  \fi%
}
\newcommand{\lmEnd}{\thEnd}

\newcommand{\cuz}{\ensuremath{\mathrel{\because}}\xspace}
\newcommand{\bcuz}{\linebreak[1]\cuz}

\hyphenation{oper-and oper-ands}
\hyphenation{look-ahead}
\hyphenation{memo-ization}

% I like to silence underfull hbox messages.
% This is syntactic sugar for doing that.
\newenvironment{MYsloppy}[1][3em]{\par\tolerance9999 \emergencystretch#1\relax}{\par}
% This form allows the resetting of hbadness, which may be necessary to
% shut up an "underfull" warning.
\newenvironment{MYsloppyB}[2]{\par\tolerance9999 \emergencystretch#1 \hbadness#2\relax}{\par}
% This form is for a trick:  Tolerances are evaluated line by line, so a tolerance
% less than 9999 may produce a better looking paragraph and reduce the "badness".
\newenvironment{MYsloppyC}[3]{\par\tolerance#3 \emergencystretch#1 \hbadness#2\relax}{\par}

\newlength\stextwidth
\newcommand\makesamewidth[3][c]{%
  \settowidth{\stextwidth}{#2}%
  \makebox[\stextwidth][#1]{#3}%
}

\title
  [Lexing and AI Tokens]
  {Lexical Analysis with AI Tokenization: An Approach}

\author{Jeffrey Kegler}
\ifdraft{
    % legacy draftwatermark options -- update?
    \SetWatermarkLightness{0}
    \SetWatermarkText{DRAFT \DTMnow{} DRAFT}
    \SetWatermarkAngle{0}
    % \SetWatermarkScale{1}
    % \SetWatermarkHorCenter{1.5in}
    \SetWatermarkVerCenter{.5in}
}{}
\ifdraft{ \thanks{DRAFT as of \DTMnow} }{}
\date{\DTMnow.}

\newcommand{\tpb}{\url{try\_push\_byte}\xspace}
\newcommand{\tpbb}{\url{try\_push\_byte(b)}\xspace}
\newcommand{\al}{\url{allowed\_lexemes}\xspace}
\newcommand{\llguidance}{{\tt llguidance}\xspace}

\begin{document}

\maketitle

\section{About this document}
\label{sec:about-me}

This document outlines a method for optimizing mask computation in
Guidance.
It assumes some familiarity with the code in
\llguidance\cite{llguidance}.

\section{Conventions}
\noindent $\bullet$ ``Iff'' (or ``iff'') abbreviates
	``if and only if''.

\noindent $\bullet$ Ranges are inclusive start,
	exclusive end, so that, for example,
		\begin{gather*}
			\element{(\texttt{"abcd"})}{0,2} = \texttt{"ab"} \text{, and} \\
			\element{(\texttt{"abcd"})}{2,3} = \texttt{"c"}.
		\end{gather*}

\noindent $\bullet$ \TRUE is a boolean (or optional boolean) true; and
        \FALSE is a boolean (or optional boolean) false.

\noindent $\bullet$ The ``because'' symbol ($\cuz$) is used in equations to
        separate the statement of fact from the reasons for it.
        It allows the reader more easily to follow the reasoning
        behind the statement of fact.

\noindent $\bullet$ Parenthesized references, for example ``(Fig5:13)'',
        are often used.  They are of the form
        \[ \texttt{`('} \cat \V{tag} \cat \V{refNo} \cat \texttt{`:'} \cat \V{pageNo} \cat \texttt{`)'} \]
        where \V{tag} is a tag, \V{refNo} is a reference number,
        and \V{pageNo} is a page number.
        Allowed tags are ``Eq'' for equation,
        and ``Fig'' for figure.
        Page number and its preceding colon separator may be omitted.
        When the page number is omitted for an equation,
        the tag may be as well, so that ``(Eq12:10)'' becomes ``(12)''.

\noindent $\bullet$ Tilde ($\sim$) is the ``matches'' operator, so that
        $\V{s} \sim \V{recce}$ is true iff the string \V{s}
        matches the recognizer \V{recce}.

\section{Summary}

\FloatBarrier

The optimization suggested here works by reducing the number of calls
of \tpb.\footnote{%
See Figure \ref{fig:try-push-byte} on page~\pageref{fig:try-push-byte},
    which contains a code snippet that is similar to, and taken from,
    \url{https://github.com/microsoft/llguidance/blob/0ca091a701a50134e0503fa03c5c12b206e182a3/toktrie/src/toktree.rs\#L945}.
}
\begin{figure}
\begin{lstlisting}
    while p < endp {
        r.pop_bytes(next_pop);
        let n = &self.nodes[p];
        let b = n.byte();
        // Click ruby slipper heels here
        if r.try_push_byte(b) {
            toks.allow_token(n.token_id().
                unwrap_or(defl_tok)
            );
            // ... stuff here ...
        } else {
            // ... other stuff here ...
        }
    }
\end{lstlisting}
\caption{Ruby Slippers Click Point%
    \label{fig:try-push-byte}%
}
\end{figure}
The optimization prefaces
(and hopefully usually replaces)
the call to \tpb with a small
set of references (one for each of a subset of the allowed
lexemes) to a cache containing
optional-boolean duples.
The set, and the optional-boolean duples,
are location-free ---
free of per-location cost in time.
(We abbreviate location-free as LF.)

The optional-boolean duples
are location-free
because they do not vary by location,
and therefore may be calculated once
and cached.
The allowed lexemes set is location-free
because it will have already been calculated for each location
for other purposes, and therefore imposes
no new costs.\footnote{%
        We ignore for the moment the slight complication
        and insignificant additional cost
        of computing the token-consistent lexemes,
        a subset of the allowed lexemes.
        See Section \ref{sec:-token-consistent lexemes}
        on page \pageref{sec:-token-consistent lexemes}.
}

The optional-boolean duples guide traversal of the token trie.
The first optional boolean of the duple is the LIVE-bit.
The LIVE-bit, when true, tells us to continue
trie traversal below the current node.
When false,
the LIVE-bit tells us not to traverse more deeply into
the token trie.
In addition, there is an EOL-bit, which tells us if
we are at the end of a lexeme (EOL).

Some lexemes will be resistant to the approach
outlined in this paper.
We will call these ``tough'' lexemes.
Tough lexemes should be sparse and will be defined
and discussed later\footnote{%
        See Section~\ref{sec:lexeme-slices}
        on page~\ref{sec:lexeme-slices}%
}.

We use the LIVE-bit to avoid most trie traversal,
without incurring the cost of a \tpb call.
Calls to \tpb
need only be made at EOL,
and for tough lexemes.

\section{The basic ideas}
\subsection{Location independence}

The first basic idea behind the suggestions in this document is
the well-known one of taking invariant code called repeatedly,
and arranging for it to be called only once.\cite{wiki-loop-invariant}
In our case, instead of moving the invariant code before the repeating
logic,
we may compute its value once and cache it.\footnote{%
	See Section \ref{sec:caching}
	on page~\pageref{sec:caching}.}

To be ``invariant'' in a sense useful for us,
the result logic must be ``location-independent'' (LI)
in the sense that it produces the same result
regardless of the parse location at which it is called.
Logic which is not location-independent is
called ``location-dependent''.

\subsection{The Ruby Slippers}

The second basic idea behind this document is more
aggressive use of the Ruby Slippers.
The Ruby Slippers is
a parsing technique discovered independently by Jeffrey Kegler%
\cite{Kegler2011a}\cite{Kegler2011b}\cite{Kegler2023}
and
Michal Moskal\cite{llguidance}.
It takes advantage of the ability of certain variants of the Earley
parser to tell the application
exactly which terminals will be acceptable at
any point in the parse.
This allows the application to change the lexeme stream to match
the parser's expectations.
The application could, for example, invent a lexeme on the fly
to accommodate the parser.\footnote{%
    The name ``Ruby Slippers'' comes from a incident in the movie
    {\it Wizard of Oz}.  In it Dorothy, the protagonist, is trying
    to return to her home in Kansas.  After many adventures she
    discovers that a pair of ruby slippers, which she has been
    wearing throughout the movie, grant her this ability.
    She has merely to click her heels and wish.}

The Ruby Slippers are already in use
in \llguidance.
An \al vector is computed,
and applied at certain points.

Looking ahead
in this document, we are going to claim
that the Ruby Slippers can be used earlier and more extensively,
and that most of the work of applying the
Ruby Slippers is location-independent.
It is hoped that this will allow considerable savings in time.

The need to access information about the stack is often
seen as an obstacle to location-independence:
Any computation which refers to the stack, it is thought,
must be location-dependent.\footnote{%
	For example,
	from Section 1, ``Introduction'' in \cite{XGrammar2024}:
	``CFG interpretation
	requires a stack state that tracks the recursive rules matched
	so far, making it impossible to precompute and cache all
	combinatorial combinations of stack patterns ahead of time.''}
We can use the Ruby Slippers, however, to make
most computation involving the stack location-independent.

To do this, we note that the only stack information we care
about is the list of ``allowed lexemes'', and information
about them.
The information about the allowed lexemes is location-independent,
and, in a Ruby-Slippers-ready implementation of the Earley algorithm,
like \llguidance,
the list of allowed lexemes is quickly found.
In fact, in \llguidance, the list of allowed lexemes
is already computed as \al,
so that it comes at literally zero cost.
For our purposes, therefore, the only cause of location-dependence will
be reference to portions of the input too early
to be found in the token trie.\footnote{%
             Optimization that incorporates the
             pre-token-trie input is a topic
             for future research.}

The results of the LF logic are booleans,
which are cached and used to avoid
calls to \tpb.
Using this optimization,
\tpb typically will only be called
when a new lexeme is ready to be accepted.
The exception is a minority of instances,
where the logic necessary to determine when
a new lexeme is ready to be accepted
cannot be made LF.
In those cases,
the cached booleans will be overapproximations,
and \tpb will be used as a fallback.

\needspace{3in}
\FloatBarrier
\section{The structure of the byte stream}
\label{sec:byte-stream}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
	\multicolumn{2}{c}{TB} &
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\rule{30pt}{0pt} &
	\multicolumn{2}{c|}{ALA} &
\multicolumn{2}{p{72pt}}{\centering Current} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
	\multicolumn{2}{p{72pt}|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{p{30pt}|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{p{30pt}|}{\rule{30pt}{0pt}} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-5}
	\multicolumn{2}{|p{72pt}|}{\centering \hyphenpenalty=10000 accepted lexeme} &
	% 30pt * 5 + 12pt * 4 = 198pt
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt} working lexeme}
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-6}
\rule{30pt}{0pt} &
	\multicolumn{2}{|p{72pt}|}{\centering committed token} &
	% 30pt * 3 + 12pt * 2 = 114pt
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt} working token} &
        \rule{30pt}{0pt} \\
	% ===
\cline{1-4}\cdashline{5-7}
	\multicolumn{4}{|p{156pt}|}{\centering seen input} &
	\multicolumn{3}{|p{114pt}}{\centering unseen input} \\
\cline{1-4}\cdashline{5-7}
\end{tabular}
\par\vspace{12pt}
\noindent
``Current'' is Current location in the byte stream. \\
``ALA'' is the Allowed Lexeme Anchor. \\
``TB'' is the Toktrie Base. \\
\vspace{6pt}
\caption{Input structure}
\label{fig:input-1}
\end{figure}

\FloatBarrier

We assume some knowledge of the codebase of \llguidance.
We recall that, to perform the mask computation,
we simulate byte streams
which are divided into tokens,
and check them for acceptability against a parser which divides that same byte stream into lexemes.
From the parser
we are given a list of acceptable lexemes.
We want to use this to determine which tokens are consistent with the parse so far.
Once we know which tokens are parse-consistent,
we can produce a token mask,
which in turn will allow us to sample a token.

To determine the acceptable tokens, we traverse a trie of the tokens,
implicitly checking the tokens against all possible byte streams.
Every node in the trie traversal implies a single byte stream,
which may be seen as structured according to the scheme in
\Figref{input-1}.

In Figure \ref{fig:input-1}
and our other
byte stream diagrams, we have identified
\begin{itemize}
	\item the most recently accepted lexeme,
	\item the most recently committed token,
	\item a lexeme in progress (aka the ''working lexeme''), and
	\item a token in progress (aka the ''working token'').
\end{itemize}
In the byte stream, we note three locations of special significance:
\begin{itemize}
	\item The current location, which is the location in the input stream
		corresponding to our current position in the our token trie traversal.
		We abbreviate this as \V{Current}.
	\item The ``toktrie base'', that is, the start location for our toktrie
		traversal, which we abbreviate \V{TB}.
		\V{TB} is at the end of the last committed token,
		if it exists, and at the start of parsing otherwise.
	\item The location for which we calculated the allowed lexemes,
		that is, the ``allowed lexeme location''.
		We abbreviate this as \V{ALA}.
		\V{ALA} is at the end of the last accepted lexeme,
		if it exists, and at the start of parsing otherwise.
\end{itemize}

It is always the case the current location is at or after TB:
\begin{equation}
\label{eq:invariant-1}
\V{TB} \le \V{Current}.
\end{equation}
It is also always the case the current location
is at or after the ALA:
\begin{equation}
\label{eq:invariant-2}
\V{ALA} \le \V{Current}.
\end{equation}

Of special interest to us will be the frame:
\begin{definition}
        \label{df:frame}
        The \textbf{frame} is the set of locations
        before the current location,
        and including portions of both the working lexeme,
        and the working token.
        The portion of the working lexeme in the frame
        is called the \textbf{framed lexeme slice}\footnote{%
                        Slices are defined in
                        Section~\ref{sec:lexeme-slices}
                        on page~\pageref{sec:lexeme-slices}.
                }
        or \textbf{framed lexeme}.
        The portion of the working token in the frame is
        called the \textbf{framed token string}
        or \textbf{framed token}.
\end{definition}

For ease of drawing,
and without loss of generality,
our byte stream diagrams
will make several assumptions.
We will assume
there is a last committed token and
a last accepted lexeme.
And, while the invariants of
\eqref{eq:invariant-1} and \eqref{eq:invariant-2}
will always be obeyed,
otherwise our byte stream diagrams may make arbitrary
assumptions about the relative length of the tokens and lexemes.
For example, \Figref{input-2}
is similar to \Figref{input-1}.
except that, while Figure \ref{fig:input-1} shows a working
lexeme that ends {\bf before} the working token,
Figure \ref{fig:input-2} shows a working
lexeme that ends {\bf after} the working token.

The \V{ALA} may occur before or after the \V{TB}.
Where
\begin{equation}
\label{eq:lexeme-offset}
	\V{off} = \V{TB} \subtract \V{ALA},
\end{equation}
we call \V{off} the
{\bf lexeme offset}\label{loc:lexeme-offset}.

\begin{definition}[Token trie variables]
        \label{df:token-trie}
\noindent
Let \V{node} be a token trie node.
Then the following are true:
\begin{MYsloppy}
\begin{itemize}
\item \VFA{path}{node} is the path from the trie root
to \V{node}, treated as a vector of nodes.
\item
\size{\VFA{path}{node}}
is the length of \VFA{path}{node}.
Abusing notation a bit, we also write
\size{\VFA{path}{node}} as \Vsize{node}.
\Vsize{node} is also called the ``depth''
of \V{node}.
\item
\FA{toString}{\VFA{path}{node}} is
the node vector \VFA{path}{node},
mapped to the bytes that label the nodes.
The result is a sequence of bytes,
and therefore a string.
We usually overload the notation
and abbreviate \FA{toString}{\VFA{path}{node}}
as \VFA{toString}{node}.
\dfEnd
\end{itemize}
\end{MYsloppy}
\end{definition}

\section{Lexeme slices}
\label{sec:lexeme-slices}

Lexeme slices are like string slices, and are represented similarly,
so that $\Velement{lex}{0,2}$ is a lexeme which matches the first two
characters of a string which matches \V{lex} and $\Velement{lex}{2,3}$
is a lexeme which matches the third character of a string which matches
\V{lex}.

In this document, we refer to a lexeme slice as location-independent (LI)
if the slice matches correctly regardless of any earlier bytes in the
string.
Here are some examples of lexeme slices:
The lexeme
\begin{equation}
	\label{eq:ex-fixed}
    \element{(\texttt{/abcd/})}{2,3} = \texttt{/c/}
\end{equation}
is an LI slice, because the string \texttt{"c"}
will always match the third character of any string
which matches $\texttt{/abcd/}$.

The lexeme
\begin{equation}
	\label{eq:ex-no-slice}
    \element{(\texttt{/(aaaaaa|bbbbbb)/})}{2,3}
\end{equation}
\noindent
does not have an LI slice.
To see why, we first note that
the third character of \eqref{eq:ex-no-slice}
must be either
\texttt{"a"} or \texttt{"b"}.
If the third character is \texttt{"a"},
\eqref{eq:ex-no-slice}
will not match the third character of
\texttt{"bbbbbb"} even though
\texttt{"bbbbbb"} matches
\texttt{/(aaaaaa|bbbbbb)/}.
If the third character is \texttt{"b"},
\eqref{eq:ex-no-slice} will not match the third character of
\texttt{"aaaaaa"} even though
\texttt{"aaaaaa"} matches
\texttt{/(aaaaaa|bbbbbb)/}.
The lexeme $\element{(\texttt{/(aaaaaa|bbbbbb)/})}{2,3}$
can be dealt with by overapproximation
(see Section \ref{sec:overapproximation}
on page~\pageref{sec:overapproximation}).

Because the set of prefixes of a regular language
is always a regular language,
every slice which begins at location
0 of the lexeme is an LI slice.
For example,
\begin{equation}
	\label{eq:ex-factored}
    \element{(\texttt{/(aaaaaa|bbbbbb)/})}{0,3}
		= \texttt{/(aaa|bbb)/}
\end{equation}
\noindent%
is an LI slice.

Kleene star regular expressions often have LI slices.
\begin{equation}
	\label{eq:ex-kleene}
    \element{(\texttt{/a*/})}{2,4}
		= \texttt{/aa/}
\end{equation}
is an LI slice.

\needspace{3in}
Case-insensitive lexemes
are not a problem for slicing.
Writing case-insensitive \texttt{/lorem/} as
\texttt{/[Ll][Oo][Rr][Ee][Mm]/},
we see that
\begin{equation}
	\label{eq:ex-case-insensitive}
	\element{(\texttt{/[Ll][Oo][Rr][Ee][Mm]/})}{2,3} = \texttt{/[Rr]/}
\end{equation}
is an LI slice.

If there is a range for which there is no LI slice
for a lexeme,
we say that it is ``unsliceable''.
When slicing a lexeme is problematic,
we say that the lexeme is ``tough''.

We consider cases:

\begin{itemize}
	\item Every fixed string is sliceable,
and none of them are tough.
In practice, most
lexemes are fixed strings.
\item
When a lexeme has no Kleene star,
it is sliceable by ``factoring'' it into fixed
strings.
Some factorings may be exponential, however,
so that regular expression lexemes,
even without Kleene stars, can be tough.
\item
	Not all Kleene star regular expressions
	are sliceable, but many are,
	as we saw in \Eqref{ex-kleene}.
\item Lexemes can be many other things besides regular expressions,
including subgrammars.
Some of these problematic lexemes may be sliceable nonetheless.
For example, the application could specify explicitly
how they can be sliced.
But many of these will be tough lexemes.
\end{itemize}

For calculating when we are at the end of a lexeme,
we will be interested in \VFA{Rem}{\V{lex},\V{pos}},
the slice which, starting at position \V{pos} in \V{lex},
is the ``remainder'' of \V{lex}.
This can be calculated as
\begin{equation}
        \label{eq:lex-rem}
        \VFA{Rem}{\V{lex},\V{pos}} = \Velement{lex}{ \, \V{pos}, \Vsize{lex} \, }.
\end{equation}

\section{Overapproximation}
\label{sec:overapproximation}

Above, we introduced the idea of tough and unsliceable lexemes.
These can be handled with overapproximation.
Our overapproximations
must not reject any matching lexemes (``false negatives''),
but they may accept non-matching lexemes (``false positives'').

As an example of overapproximation, we revisit
\Eqref{ex-no-slice}:
\begin{equation}
	\label{eq:unsliceable}
    \element{(\texttt{/(aaaaaa|bbbbbb)/})}{2,3}
\end{equation}
is not sliceable.
But a good overapproximation to
\eqref{eq:unsliceable} is
\begin{equation}
	\label{eq:approx}
\texttt{/[ab]/},
\end{equation}
which matches either
\texttt{"a"} or \texttt{"b"}.
\eqref{eq:approx} avoids false negatives,
as required.
\eqref{eq:approx} does return false positives,
but only in the case of one byte out of
the 256 possibilities,
so the accuracy of
\eqref{eq:approx} is high.

The overapproximation of last resort is a ``wildcard'',
which matches everything.
Almost all lexemes will be sliceable in practice,
and an implementation is likely to find it most convenient
to treat all lexemes as if they were sliceable.
The wildcard approximation allows this.

\section{Token-consistent lexemes}
\label{sec:-token-consistent lexemes}

At the start of parse, and after every lexeme,
there is a set of ``allowed lexemes''.
The allowed lexemes are those which, if accepted,
can result in a valid parse,
according to the parser.
\llguidance already calculates the allowed lexemes,
which it tracks in its \al vector.

Recall the location for which the allowed lexemes
are calculated is \V{ALA}.
The location where the last committed token ends
is \V{TB}.
If $\V{TB} > \V{ALA}$, it becomes possible
that an allowed lexeme might be inconsistent
with the committed tokens.

For example, if the lexemes {\tt foreach} and {\tt while} are
allowed at location $\ell$,
and the token {\tt "wh"} is committed, starting at
$\ell$,
then only the lexeme {\tt while} will be consistent with
the committed tokens.
While according to the parser, the lexeme {\tt foreach}, if accepted,
could result in a valid parse,
the lexeme {\tt foreach} would be inconsistent with the
committed tokens
and would cause the parse to fail.

We therefore, whenever we commit a token,
calculate the subset of the allowed lexemes
which can still produce a parse both in terms
of the parser and the tokenization.
We call these the ``token-consistent lexemes''.

The token-consistent lexemes might be equivalent
to the allowed lexemes.
When $\V{TB} \le \V{ALA}$, this will always be
the case.
A token-consistent lexeme is always an allowed lexeme.

Allowed lexemes should be sparse,
and token-consistent lexemes will be even more sparse.\footnote{%
	For \cite{XGrammar2024}
	the nearest approximation to ``token-consistent lexemes'' is
	their ``context-dependent tokens''.
	In one experiment, with a JSON parser,
	they put ``context-dependent tokens'' at ``less than 1\%
	(1134 out of 128k)"
	(Section 3.1, ``Adaptive Token Mask Cache'').
	Our Earley engine has more information about the parse
	than the PDA of \cite{XGrammar2024}, so we would expect
	``token-consistent lexemes'' to be even sparser
	than ``context-dependent tokens''.
	Comparing statistics from the two approaches, however,
	is a risky business.
	We also should keep in mind that JSON is, by design,
	a very easy to parse language,
	so should naturally yield a low count of
	both ``token-consistent lexemes'' and
	``context-dependent tokens''.}

\needspace{3in}
\section{Calculating LIVE and EOL at each byte location}

We must calculate a per-byte-location value for LIVE and
EOL.
Let only one lexeme
be token-consistent
at $\ell$, a particular byte location.
Call that one lexeme, \V{lex}.
Let \VFA{LIVE-bit}{lex} be the LIVE-bit of \V{lex},
and let \VFA{EOL-bit}{lex} be the EOL-bit of \V{lex}.
Then
the value of LIVE for $\ell$ is
\begin{equation}
        \FA{LIVE}{\ell} = \VFA{LIVE-bit}{lex},
\end{equation}
and value of EOL for $\ell$ is
\begin{equation}
        \FA{EOL}{\ell} = \VFA{EOL-bit}{lex}.
\end{equation}

The most common count of token-consistent lexemes
per byte location will be one.
But it will by no means be rare for
multiple lexemes to be token-consistent
at a single byte location,
and we must know how to deal with that.
The LIVE value of a location is the logical-or of
the location's set of LIVE-bit values,
and the EOL value of a location is the logical-or of
the location's set of EOL-bit values.

More precisely,
let \V{tcls} be the set of token-consistent lexemes
at the location $\ell$.
Then the LIVE value at $\ell$ is
\begin{equation}
        \FA{LIVE}{\ell} = \bigvee \; \lbrace \VFA{LIVE-bit}{l} \,\mid\, \V{l} \in \V{tcsls} \rbrace,
\end{equation}
and the EOL value at $\ell$ is
\begin{equation}
        \FA{EOL}{\ell} = \bigvee \; \lbrace \VFA{EOL-bit}{l} \,\mid\, \V{l} \in \V{tcsls} \rbrace.
\end{equation}

\section{Frames with positive offsets}
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
\multicolumn{2}{c}{TB} &
\rule{30pt}{0pt} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\rule{30pt}{0pt} &
\multicolumn{2}{c|}{ALA} &
\multicolumn{2}{c}{Current} &
\rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\multicolumn{2}{c|}{} &
\multicolumn{1}{c|}{} &
\multicolumn{1}{c|}{} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} &
        \rule{30pt}{0pt} \\
\cline{1-4}\cdashline{5-7}
	\multicolumn{2}{|p{72pt}|}{\centering \hyphenpenalty=10000 accepted lexeme} &
	% 30pt * 5 + 12pt * 4 = 198pt
	\multicolumn{5}{|p{198pt};{2pt/2pt}}{\centering\vspace{-1pt}working lexeme} \\
\cline{1-4}\cdashline{5-7}
\rule{30pt}{0pt} &
	\multicolumn{2}{|p{72pt}|}{\centering committed token} &
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working token} &
        \rule{30pt}{0pt} \\
\cline{1-4}\cdashline{5-7}
	\multicolumn{4}{|p{156pt}|}{\centering seen input} &
	\multicolumn{3}{|p{114pt}}{\centering unseen input} \\
\cline{1-4}\cdashline{5-7}
\end{tabular}
\vspace{6pt}
\caption{Working lexeme with positive offset}
\label{fig:input-2}
\end{figure}

In this section we consider the case
where the start of the token is after the
start of the lexeme, so that TB
is properly inside the lexeme.
We defined the lexeme offset as \V{off}
in equation \Eqref{lexeme-offset}:
\[
	\V{off} = \V{TB} \subtract \V{ALA}.
\]
From \Eqref{lexeme-offset},
and from \Figref{input-2},
it can be seen that a lexeme slice that begins
after TB has a positive offset.

We recall now the definitions
of framed lexeme and framed token \Dfref{frame}.
We will use the definitions of \V{node}, etc.,
in Definition \Dfref{token-trie}
to state the
framed lexeme and framed token values.

If \V{off} is positive,
as in Figure~\ref{fig:input-2},
so that $\V{TB} > \V{ALA}$, then
\begin{equation}
\label{eq:positive-framelex}
        \FA{FrameLex}{\V{lex}, \V{off}} = \Velement{lex}{\V{off}, \Vsize{node}+\V{off}}
\end{equation}
is value of the framed lexeme.

Next, we want the value of the framed token,
which we will call $\FA{FrameTok}{\V{node},\V{off}}$.
We recall that \VFA{toString}{node} is
the string implied by \V{node} in the token trie.
If \V{off} is positive, so that $\V{TB} > \V{ALA}$,
the entire token trie is inside the frame,
so that \VFA{toString}{node} is identical
to the framed token:
\begin{equation}
\label{eq:positive-frametok}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node}.
\end{equation}

Finally, in order to determine if we are at EOL,
we want the value of the remaining lexeme,
the framed lexeme plus the portion of it extending beyond the
frame.
The framed lexeme starts at \V{off},
so we have
\begin{equation}
\label{eq:positive-remlex}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}}.
\end{equation}

\FloatBarrier
\section{Frames with negative offsets}
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
\begin{tabular}{p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}p{30pt}}
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
        \multicolumn{2}{c}{ALA} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} \\
	% ===
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} &
        \multicolumn{2}{c|}{TB} &
        \multicolumn{2}{c}{Current} \\
	% ===
	\rule{30pt}{0pt} &
        \multicolumn{2}{c|}{} &
	\multicolumn{1}{c|}{\rule{30pt}{0pt}} &
	\multicolumn{1}{c|}{\rule{30pt}{0pt}} &
	\rule{30pt}{0pt} &
	\rule{30pt}{0pt} \\
	% ===
\cline{1-5}\cdashline{6-7}
\multicolumn{4}{|c|}{accepted lexeme} &
	\multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working lexeme} \\
\cline{1-5}\cdashline{6-7}
        \rule{30pt}{0pt} &
        \multicolumn{2}{|p{6em}|}{\centering committed token} &
        \multicolumn{3}{|p{114pt};{2pt/2pt}}{\centering\vspace{-1pt}working token}
        \\
	% ===
\cline{1-5}\cdashline{6-7}
\multicolumn{5}{|c|}{seen input} &
        \multicolumn{2}{|c}{unseen input} \\
\cline{1-5}\cdashline{6-7}
\end{tabular}
\vspace{6pt}
\caption{Working lexeme with negative offset}
\label{fig:input-3}
\end{figure}

\FloatBarrier

We now consider the case
where the start of the token is before the
start of the lexeme, so that ALA
is properly inside the token.
Recalling our definition of the offset \Eqref{lexeme-offset},
\[ \V{off} = \V{TB} \subtract \V{ALA}, \]
and looking at \Figref{input-3},
we see that when $\V{TB} < \V{ALA}$,
the offset will be negative.

When the offset is negative,
the frame then includes the entire lexeme up to
the current location, so that
the framed lexeme is
\begin{equation}
\label{eq:negative-framelex}
        \FA{FrameLex}{\V{lex}, \V{off}} = \Velement{lex}{0, \Vsize{node}+\V{off}}.
\end{equation}

When \V{off} is negative, the frame only includes
a lower portion of the token trie,
whose length is the absolute value of the offset,
$\VFA{abs}{off}$.
Accordingly,
\begin{equation}
\label{eq:negative-frametok}
        \FA{FrameTok}{\V{node},\V{off}} =
		\element{(\VFA{toString}{node})}{\Vsize{node}+\V{off}, \Vsize{node}}.
\end{equation}

The remaining lexeme, again,
is the framed lexeme plus the portion of it extending beyond the
frame.
Since the ALA is properly inside the frame,
the remaining lexeme is the entire lexeme:
\begin{equation}
\label{eq:negative-remlex}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, 0} = \V{lex}.
\end{equation}

\section{Computing the bits}

The value of LIVE-bit is
\begin{equation}
	\label{eq:live-bit}
        \V{LIVE-bit} = \begin{cases}
                \; \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}}, \\
                \qquad \qquad \text{if \FA{FrameLex}{\V{lex}, \V{off}} exists.} \\
                \; \text{\FALSE, otherwise.}
        \end{cases}
\end{equation}
The value of EOL-bit is
\begin{equation}
	\label{eq:eol-bit}
        \V{EOL-bit} = \begin{cases}
                \; \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
                \qquad \qquad \text{if $\V{LIVE-bit} = \TRUE$.} \\
                \; \text{\FALSE, otherwise.}
        \end{cases}
\end{equation}
In \eqref{eq:live-bit} and \eqref{eq:eol-bit},
we recall that $\V{s} \sim \V{recce}$ is true iff the string \V{s}
matches the recognizer \V{recce}.

It is important that it be the case that \tpb is true
only if LIVE-bit in \eqref{eq:live-bit} is true.
To allow for overapproximation,
it may also be the case that \tpb is false
if LIVE-bit is true:
a ``false positive''.
It must never be the case that \tpb is true
when LIVE-bit is false:
a ``false negative''.

In more implementation-oriented terms,
in the scheme outlined in the paper,
LIVE-bit predicts whether a call to \tpb
will return true,
and \tpb is only called when LIVE-bit is true.
However, there may be ``false positives'':
LIVE-bit may falsely predict that a call to \tpb
will return true, in which case \tpb is used to check the prediction.

There must be no ``false negatives''.
If it ever happens that
LIVE-bit is false,
when a call to \tpb would return true,
a correct parse might be missed,
and the algorithm might fail.

For the EOL-bit, the requirement to avoid false negatives is
the same.
A spuriously true EOL-bit, that is a ``false positive'', results
in an unnecessary call to \tpb.
The unnecessary call to \tpb has a cost in time, but is
otherwise harmless.
A ``false negative'' for the EOL-bit may result in a missed parse.

Allowing false positives enables the use of lexemes that overapproximate.
Overapproximation is useful for tough lexemes.
In the face of overapproximation, unnecessary calls
to \tpb might be made.
But the number of unnecessary calls is expected to
be manageable.
In practice,
token-consistent lexemes are sparse,
most lexemes are sliceable,
and most tough lexemes have good overapproximations.

\section{Caching}
\label{sec:caching}

For every node \V{node},
every lexeme \V{lex},
and every offset \V{off},
our optimization code must access the value of the LIVE-bit and
the EOL-bit.
We call
\begin{equation}
\label{eq:ruby-triple}
        \V{ruby} = (\V{node}, \V{lex}, \V{off})
\end{equation}
a ``Ruby triple'',
and define \Fname{Ruby} as a partial function from the set
of Ruby triples to the set of pairs of optional booleans,
such that
\begin{equation}
\label{eq:ruby-function}
        \FA{Ruby}{\V{node}, \V{lex}, \V{off}} = (\V{live}, \V{eol}),
\end{equation}
where \V{live} is the LIVE-bit for \V{ruby}, and
\V{eol} is the EOL-bit\footnote{%
        See Section~\ref{sec:medial-bit}
        on page~\pageref{sec:medial-bit}
        for a discussion of use of a MEDIAL-bit as
        an alternative to an EOL-bit.}
for \V{ruby}.

Above we have discussed how to compute
\eqref{eq:ruby-function}.
When the value of \eqref{eq:ruby-function}
is location-free, we will often want to cache it.

When \V{lex} is sliceable,
the value of \eqref{eq:ruby-function}
depends only on the values of
\V{node}, \V{lex}, and \V{off}
so that
the value of
\FA{Ruby}{\V{node}, \V{lex}, \V{off}}
is location-free.
We can make \eqref{eq:ruby-function}
a total function by using the wildcard slice
when \V{lex} is tough.

It will not make sense to cache
\FA{Ruby}{\V{node}, \V{lex}, \V{off}} in all cases.
For small absolute values of \V{off}, the cache
will be dense,
and the likelihood of hits in a fully pre-populated
cache will be high.
In this case,
pre-computation at grammar compile time makes sense.
Additionally, computing many of the values
for low \V{off}-valued Ruby triples
in a single token trie
traversal might allow for optimizations.

On the other hand,
since lexemes may be of arbitrary length,
pre-computation of all Ruby triple values
is not just costly in practice,
but impossible in theory.
Further,
in practical applications,
the lexemes of
very large absolute values of \V{off}
will usually be very long strings or here-documents.
Long strings and here-documents
typically will not be repeated exactly,
so that the likelihood of cache hits would
be very low.\footnote{%
        From more on long lexemes, like strings and here-documents,
        see Section~\ref{sec:strings} on page~\pageref{sec:strings}.
}
Therefore, for absolute values of \V{off}
above a certain threshold,
it is likely to make sense to not cache the
value of Ruby triples.

Many caching refinements are possible.
It may make sense to vary the caching strategy by lexeme,
or to take into account, not just the absolute value \V{off},
but its sign.

\section{Fixed string example}
\label{sec:examples}

The example in the section will follow the recognition
of a token-consistent fixed string lexeme, byte by byte.
The lexeme will be
\begin{equation}
\label{eq:fixed-string-lexeme}
        \V{lex} = \texttt{/abcdef/}.
\end{equation}

We will assume that we have already committed
a token which covers the lexeme's first three bytes:
\texttt{"abc"},
so that our trie base (TB)
is 3 bytes after the
allowed lexeme anchor (ALA).
In other words, our lexeme offset is 3:
\begin{equation}
        \label{eq:fixed-string-offset}
	\V{off} = (\V{TB} \subtract \V{ALA}) = 3.
\end{equation}

We are trying to sample a token which covers
the last three bytes:
\texttt{"def"}.
We will show our progress
byte by byte
until the EOL.

\needspace{3in}
\FloatBarrier

\subsection {Byte 1: not at EOL}
{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
            Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
             }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{...\texttt{"abc"}} & \\
		token string & & \\
		\hline
		Framed token & & \texttt{"d"} \\
		\hline
		Lexeme	& \multicolumn{2}{|c|}{\texttt{/abcdef/}} \\
		\hline
		Framed lexeme & & \texttt{/d/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Fixed string example}
\label{fig:fixed-byte-1}
\end{figure}
} % group for floatstyle

\Figref{fixed-byte-1} shows the case where
\VFA{toString}{node},
the string implied by \V{node} of the token trie,
is \texttt{"d"},
\begin{equation}
        \label{eq:fixed-byte-1-tostring}
        \VFA{toString}{node} = \texttt{"d"} \cuz \Figref{fixed-byte-1}.
\end{equation}
so that
\begin{equation}
        \label{eq:fixed-byte-1-nodesize}
        \Vsize{node} = 1 \cuz \eqref{eq:fixed-byte-1-tostring}, \Figref{fixed-byte-1}.
\end{equation}
Recall from \Eqref{fixed-string-offset} that the lexeme offset is 3,
which is positive.
The frame is \texttt{[3,4]}.

There is an framed slice.
Applying the formula for framed slices
of positive offsets,
\begin{equation}
        \label{eq:fixed-byte-1-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/abcdef/})}{3, (1+3) } \\
    = \texttt{/d/} \\
        \cuz \Eqref{positive-framelex}, \eqref{eq:fixed-string-offset},
                \eqref{eq:fixed-byte-1-nodesize}, \Figref{fixed-byte-1}.
\end{gathered}
\end{equation}

Applying the formula for the framed token of positive offsets,
\begin{equation}
        \label{eq:fixed-byte-1-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"d"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:fixed-byte-1-tostring}, \Figref{fixed-byte-1}.
        \end{gathered}
\end{equation}
and the formula for the remaining lexeme of positive offsets,
\begin{equation}
        \label{eq:fixed-byte-1-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/abcdef/}, 3} \\
                    = \texttt{/def/} \\
                \cuz \Eqref{positive-remlex}, \eqref{eq:fixed-string-offset}, \Figref{fixed-byte-1}.
\end{gathered}
\end{equation}

From these facts we can compute the LIVE-bit,
\begin{equation}
        \label{eq:fixed-byte-1-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"d"}  \, \sim \, \texttt{/d/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:fixed-byte-1-framelex}, \eqref{eq:fixed-byte-1-frametok}.
        \end{gathered}
\end{equation}
and the EOL-bit,
\begin{equation}
        \label{eq:fixed-byte-1-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
        = \texttt{"d"} \,\sim\, \texttt{/def/} \\
        = \FALSE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:fixed-byte-1-frametok}, \eqref{eq:fixed-byte-1-remlex}.
        \end{gathered}
\end{equation}

From the above, we see that we can add the following to the cache:
\[
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/abcdef/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \FALSE) \\
                \cuz \Eqref{ruby-function}, \Eqref{fixed-string-lexeme}, \Eqref{fixed-byte-1-nodesize}
                        \eqref{eq:fixed-byte-1-livebit}, \eqref{eq:fixed-byte-1-eolbit} \Figref{fixed-byte-1}.
        \end{gathered}
\]

\needspace{3in}
\FloatBarrier

\subsection {Byte 2: not at EOL}
{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{...\texttt{"abc"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"de"} \\
		\hline
		Lexeme	& \multicolumn{2}{|c|}{\texttt{/abcdef/}} \\
		\hline
		Framed lexeme & & \texttt{/de/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Fixed string example}
\label{fig:fixed-byte-2}
\end{figure}
} % group for floatstyle

In \Figref{fixed-byte-2},
\VFA{toString}{node},
the string implied by \V{node} of the token trie,
has been extended to \texttt{"de"},
\begin{equation}
        \label{eq:fixed-byte-2-tostring}
        \VFA{toString}{node} = \texttt{"de"} \cuz \Figref{fixed-byte-2}.
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-nodesize}
        \Vsize{node} = 2 \cuz \eqref{eq:fixed-byte-2-tostring}, \Figref{fixed-byte-2}.
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/abcdef/})}{3, (2+3) } \\
    = \texttt{/de/} \\
        \cuz \Eqref{positive-framelex}, \Eqref{fixed-string-offset},
                \eqref{eq:fixed-byte-2-nodesize}, \Figref{fixed-byte-2}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"de"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:fixed-byte-2-tostring}, \Figref{fixed-byte-2}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/abcdef/}, 3} \\
                    = \texttt{/def/} \\
                \cuz \Eqref{positive-remlex}, \Eqref{fixed-string-offset}, \Figref{fixed-byte-2}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"de"}  \, \sim \, \texttt{/de/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:fixed-byte-2-framelex}, \eqref{eq:fixed-byte-2-frametok}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-2-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
        = \texttt{"de"} \,\sim\, \texttt{/def/} \\
        = \FALSE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:fixed-byte-2-frametok}, \eqref{eq:fixed-byte-2-remlex}.
        \end{gathered}
\end{equation}
\begin{equation}
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/abcdef/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \FALSE) \\
                \cuz \Eqref{ruby-function}, \Eqref{fixed-string-lexeme}, \Eqref{fixed-byte-2-nodesize}
                        \eqref{eq:fixed-byte-2-livebit}, \eqref{eq:fixed-byte-2-eolbit} \Figref{fixed-byte-2}.
        \end{gathered}
\end{equation}

\needspace{3in}
\FloatBarrier

\subsection {Byte 3: EOL}
{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{...\texttt{"abc"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"def"} \\
		\hline
		Lexeme	& \multicolumn{2}{|c|}{\texttt{/abcdef/}} \\
		\hline
		Framed lexeme & & \texttt{/def/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Fixed string example}
\label{fig:fixed-byte-3}
\end{figure}
} % group for floatstyle

\VFA{toString}{node},
the string implied by \V{node} of the token trie,
is completed as \texttt{"def"},
\begin{equation}
        \label{eq:fixed-byte-3-tostring}
        \VFA{toString}{node} = \texttt{"def"} \,\cuz\, \Figref{fixed-byte-3}.
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-nodesize}
        \Vsize{node} = 3 \,\cuz\, \eqref{eq:fixed-byte-3-tostring}, \Figref{fixed-byte-3}.
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/abcdef/})}{3, (3+3) } \\
    = \texttt{/def/} \\
        \cuz \Eqref{positive-framelex}, \Eqref{fixed-string-offset},
                \eqref{eq:fixed-byte-3-nodesize}, \Figref{fixed-byte-3}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"def"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:fixed-byte-3-tostring}, \Figref{fixed-byte-3}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/abcdef/}, 3} \\
                    = \texttt{/def/} \\
                \cuz \Eqref{positive-remlex}, \Eqref{fixed-string-offset}, \Figref{fixed-byte-3}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"def"}  \, \sim \, \texttt{/def/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:fixed-byte-3-framelex}, \eqref{eq:fixed-byte-3-frametok}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:fixed-byte-3-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
        = \texttt{"def"} \,\sim\, \texttt{/def/} \\
        = \TRUE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:fixed-byte-3-frametok}, \eqref{eq:fixed-byte-3-remlex}.
        \end{gathered}
\end{equation}
\begin{equation}
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/abcdef/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \TRUE) \\
                \cuz \Eqref{ruby-function}, \Eqref{fixed-string-lexeme}, \Eqref{fixed-byte-3-nodesize}
                        \eqref{eq:fixed-byte-3-livebit}, \eqref{eq:fixed-byte-3-eolbit} \Figref{fixed-byte-3}.
        \end{gathered}
\end{equation}

\needspace{3in}
\FloatBarrier
\section {Kleene star example}

{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{...\texttt{"aaa"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"aaa"} \\
		\hline
		Lexeme	& \multicolumn{2}{|c|}{\texttt{/aa*/}} \\
		\hline
		Framed lexeme & & \texttt{/aaa/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Kleene regex star example}
\label{fig:kleene}
\end{figure}
} % group for floatstyle

Figure~\ref{fig:kleene} illustrates the handling of Kleene star
regular expressions.
We are considering
the token-consistent lexeme
\begin{equation}
        \label{eq:kleene-lexeme}
        \V{lex} = \texttt{/aa*/}.
\end{equation}
In Figure~\ref{fig:kleene}
we have committed a token ending in \texttt{"aaa"}.
The lexeme offset is
\begin{equation}
        \label{eq:kleene-offset}
	\V{off} = (\V{TB} \subtract \V{ALA}) = 3,
\end{equation}
which is positive.

\begin{equation}
        \label{eq:kleene-tostring}
        \VFA{toString}{node} = \texttt{"aaa"} \,\cuz\, \Figref{kleene}.
\end{equation}
\begin{equation}
        \label{eq:kleene-nodesize}
        \Vsize{node} = 3 \,\cuz\, \eqref{eq:kleene-tostring}, \Figref{kleene}.
\end{equation}

There is an framed lexeme\footnote{%
	For Kleene star regular expressions there will not necessarily
	be a framed lexeme.
	In that case we use overapproximation.
	See Section~\ref{sec:example-overapproximate}
	on page~\pageref{sec:example-overapproximate}
	for an
	example of overapproximation, in that case for regular
	expressions using alternatives.
}:
\begin{equation}
        \label{eq:kleene-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/aa*/})}{3, (3+3) } \\
    = \texttt{/aaa/} \\
        \cuz \Eqref{positive-framelex}, \Eqref{kleene-offset},
                \eqref{eq:kleene-nodesize}, \Figref{kleene}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:kleene-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"aaa"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:kleene-tostring}, \Figref{kleene}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:kleene-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/aa*/}, 3} \\
                    = \texttt{/aaa/} \\
                \cuz \Eqref{positive-remlex}, \Eqref{kleene-offset}, \Figref{kleene}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:kleene-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"aaa"}  \, \sim \, \texttt{/aaa/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:kleene-framelex}, \eqref{eq:kleene-frametok}.
        \end{gathered}
\end{equation}
We have now reached EOL:
\begin{equation}
        \label{eq:kleene-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
        = \texttt{"aaa"} \,\sim\, \texttt{/aaa/} \\
        = \TRUE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:kleene-frametok}, \eqref{eq:kleene-remlex}.
        \end{gathered}
\end{equation}
\begin{equation}
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/aa*/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \TRUE) \\
                \cuz \Eqref{ruby-function}, \Eqref{kleene-lexeme}, \Eqref{kleene-nodesize}
                        \eqref{eq:kleene-livebit}, \eqref{eq:kleene-eolbit} \Figref{kleene}.
        \end{gathered}
\end{equation}

\needspace{3in}
\FloatBarrier
\section {Examples with no framed lexeme}
\label{sec:example-unsliceable}

{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[H]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{\texttt{..."aaa"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"bbb"} \\
		\hline
		Lexeme	& \multicolumn{2}{|c|}{\texttt{/(aaaaaa|bbbbbb)/}} \\
		\hline
		Framed lexeme	& & none \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{An unsliceable example}
\label{fig:example-unsliceable}
\end{figure}
} % group for floatstyle

In \Figref{example-unsliceable},
we are considering the lexeme
\texttt{/(aaaaaa|bbbbbb)/}.
The lexeme offset is
\begin{equation}
        \label{eq:unsliceable-offset}
	\V{off} = (\V{TB} \subtract \V{ALA}) = 3,
\end{equation}
which is positive.

\begin{equation}
        \label{eq:unsliceable-tostring}
        \VFA{toString}{node} = \texttt{"bbb"} \cuz \Figref{example-unsliceable}.
\end{equation}
\begin{equation}
        \label{eq:unsliceable-nodesize}
        \Vsize{node} = 3 \cuz \eqref{eq:unsliceable-tostring}, \Figref{example-unsliceable}.
\end{equation}

But we have a problem:
\texttt{/(aaaaaa|bbbbbb)/} is unsliceable.
The subsections below show two solutions to this problem.
Section~\ref{sec:example-factoreda}
on page~\pageref{sec:example-factoreda}
and
Section~\ref{sec:example-factoredb}
on page~\pageref{sec:example-factoredb}
show a solution that involves factoring
\texttt{/(aaaaaa|bbbbbb)/}
into two lexemes,
one for each alternative.
Section~\ref{sec:example-overapproximate}
on page~\pageref{sec:example-overapproximate}
shows a solution that uses
overapproximation.

\needspace{3in}
\FloatBarrier
\subsection{Example of factored alternatives, part 1}
\label{sec:example-factoreda}

{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[ht]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                     \makesamewidth[c]{[TB,Current]}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{[TB,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{\texttt{..."aaa"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"bbb"} \\
		\hline
		\multirow{2}{*}{Lexemes}
			& \multicolumn{2}{|c|}{\texttt{/aaaaaa/}} \\
			 & \multicolumn{2}{|c|}{\texttt{/bbbbbb/}} \\
		\hline
		\multirow{2}{*}{Framed lexemes} & & \texttt{/aaa/} \\
		 & & \texttt{/bbb/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Factored regular expression example}
\label{fig:factored}
\end{figure}
} % group for floatstyle

One solution to the problem presented in
Section~\ref{sec:example-unsliceable}
on page~\pageref{sec:example-unsliceable}
is ``factoring''.
Any regular expression which does not use the Kleene star
can be factored into fixed string lexemes.
We note that such regular expressions might still be tough:
the number of factored strings can be large enough to make
a factoring solution impractical.

In this example, factoring is quite practical.
\texttt{/(aaaaaa|bbbbbb)/}
can be factored into the two lexemes:
\texttt{/aaaaaa/} and \texttt{/bbbbbb/}.
We will look at each in turn,
starting with
\begin{equation}
        \label{eq:factoreda-lexeme}
        \V{lex} = \texttt{/aaaaaa/}.
\end{equation}
\begin{equation}
        \label{eq:factoreda-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/aaaaaa/})}{3, (3+3) } \\
    = \texttt{/aaa/} \\
        \cuz \Eqref{positive-framelex}, \Eqref{unsliceable-offset},
                \eqref{eq:unsliceable-nodesize}, \eqref{eq:factoreda-lexeme},
                \Figref{factored}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factored-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"bbb"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:unsliceable-tostring}, \Figref{factored}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factoreda-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"bbb"}  \, \sim \, \texttt{/aaa/} \\
                = \FALSE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:factoreda-framelex}, \eqref{eq:factored-frametok}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factoreda-eolbit}
        \begin{gathered}
                \V{EOL-bit} = \FALSE \cuz \Eqref{eol-bit}, \eqref{eq:factoreda-livebit}.
        \end{gathered}
\end{equation}
\begin{equation}
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/aaaaaa/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\FALSE, \FALSE) \\
                \cuz \Eqref{ruby-function}, \Eqref{unsliceable-nodesize}, \Eqref{factoreda-lexeme},
                        \eqref{eq:factoreda-livebit}, \eqref{eq:factoreda-eolbit} \Figref{factored}.
        \end{gathered}
\end{equation}

\subsection{Example of factored alternatives, part 2}
\label{sec:example-factoredb}

In this section we continue the ``factoring'' described
in Section~\ref{sec:example-factoreda}
on page~\pageref{sec:example-factoreda},
considering the lexeme
\begin{equation}
        \label{eq:factoredb-lexeme}
        \V{lex} = \texttt{/bbbbbb/}.
\end{equation}
\begin{equation}
        \label{eq:factoredb-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
	= \Velement{(\texttt{/bbbbbb/})}{3, (3+3) } \\
    = \texttt{/bbb/} \\
        \cuz \Eqref{positive-framelex}, \Eqref{unsliceable-offset},
                \eqref{eq:unsliceable-nodesize}, \eqref{eq:factoredb-lexeme},
                \Figref{factored}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factoredb-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"bbb"}  \, \sim \, \texttt{/bbb/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:factored-frametok}, \eqref{eq:factoredb-framelex}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factoredb-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/bbbbbb/}, 3} \\
                    = \texttt{/bbb/} \\
                \cuz \Eqref{positive-remlex}, \Eqref{unsliceable-offset}, \Figref{factored}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:factoredb-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
        = \texttt{"bbb"} \,\sim\, \texttt{/bbb/} \\
        = \TRUE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:factored-frametok}, \eqref{eq:factoredb-remlex}.
        \end{gathered}
\end{equation}
\begin{equation}
        \begin{gathered}
        \FA{Ruby}{\V{node}, \texttt{/bbbbbb/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \TRUE) \\
                \cuz \Eqref{ruby-function}, \Eqref{unsliceable-nodesize}, \Eqref{factoredb-lexeme},
                        \eqref{eq:factoredb-livebit}, \eqref{eq:factoredb-eolbit} \Figref{factored}.
        \end{gathered}
\end{equation}

\subsection {Example of overapproximation}
\label{sec:example-overapproximate}

{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[H]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{%
                \makesamewidth[c]{X0XXXX0XXXX}{[ALA,TB]}%
            }
			& \multicolumn{1}{|c|}{%
                \makesamewidth[c]{X0XXXX0XXXX}{[TB,Current]}%
            }
			\\
		\hline
            Pre-frame & \multirow{2}{*}{...\texttt{"aaa"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"aaa"} \\
		\hline
            Original	& \multicolumn{2}{|c|}{ \multirow{2}{*}{\texttt{/(aaaaaa|bbbbbb)/}}} \\
            Lexeme	& \multicolumn{2}{|c|}{} \\
		\hline
            Overapproximated & \multicolumn{2}{|c|}{ \multirow{2}{*}{\texttt{/[ab][ab][ab][ab][ab][ab]/}}} \\
            Lexeme	& \multicolumn{2}{|c|}{} \\
		\hline
            Overapproximated & & \multirow{3}{*}{\texttt{/[ab][ab][ab]/}} \\
            Framed & & \\
            Lexeme Slice & & \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Overapproximated slice example}
\label{fig:overapproximate}
\end{figure}
} % group for floatstyle


A second solution to the problem presented in
Section~\ref{sec:example-unsliceable}
on page~\pageref{sec:example-unsliceable}
is overapproximation.
An excellent overapproximation for
\texttt{/(aaaaaa|bbbbbb)/} is
\begin{equation}
        \label{eq:overapproximate-lexeme}
        \V{lex} = \texttt{/[ab][ab][ab][ab][ab][ab]/}
                \, \cuz \,\Figref{overapproximate}.
\end{equation}

The lexeme offset is
\begin{equation}
        \label{eq:overapproximate-offset}
	\V{off} = (\V{TB} \subtract \V{ALA}) = 3
                \, \cuz \,\Figref{overapproximate},
\end{equation}
which is positive.
\begin{equation}
        \label{eq:overapproximate-tostring}
        \VFA{toString}{node} = \texttt{"aaa"}
                \, \cuz \, \Figref{overapproximate}.
\end{equation}
\begin{equation}
        \label{eq:overapproximate-nodesize}
        \Vsize{node} = 3 \, \cuz \, \eqref{eq:overapproximate-tostring}, \Figref{overapproximate}.
\end{equation}
\begin{equation}
        \label{eq:overapproximate-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{\V{off}, (\Vsize{node}+\V{off}) } \\
        = \Velement{(\texttt{/[ab][ab][ab][ab][ab][ab]/})}{3, (3+3) } \\
        = \texttt{/[ab][ab][ab]/} \\
        \cuz \Eqref{positive-framelex}, \eqref{eq:overapproximate-lexeme}, \eqref{eq:overapproximate-offset},
                \eqref{eq:overapproximate-nodesize}, \Figref{overapproximate}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:overapproximate-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}} = \VFA{toString}{node} \\
                = \texttt{"aaa"} \\
                \cuz \Eqref{positive-frametok}, \eqref{eq:overapproximate-tostring}, \Figref{overapproximate}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:overapproximate-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} = \FA{Rem}{\V{lex}, \V{off}} \\
                    = \FA{Rem}{\texttt{/[ab][ab][ab][ab][ab][ab]/}, 3} \\
                    = \texttt{/[ab][ab][ab]/} \\
                \cuz \Eqref{positive-remlex}, \eqref{eq:overapproximate-lexeme}, \eqref{eq:overapproximate-offset},
                        \Figref{overapproximate}.
\end{gathered}
\end{equation}
\begin{equation}
        \label{eq:overapproximate-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"aaa"}  \, \sim \, \texttt{/[ab][ab][ab]/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:overapproximate-framelex}, \eqref{eq:overapproximate-frametok}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:overapproximate-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
                = \texttt{"aaa"} \,\sim\, \texttt{/[ab][ab][ab]/} \\
        = \TRUE \\
                \cuz \Eqref{eol-bit},
                        \eqref{eq:overapproximate-frametok}, \eqref{eq:overapproximate-remlex}.
        \end{gathered}
\end{equation}
We therefore can cache a $(\TRUE, \TRUE)$
for the Ruby triple
\begin{equation}
        \begin{gathered}
                \FA{Ruby}{\V{node}, \texttt{/[ab][ab][ab][ab][ab][ab]/}, 3} = \\
                (\V{LIVE-bit}, \V{EOL-bit}) = \\
                (\TRUE, \TRUE) \\
                \cuz \Eqref{ruby-function}, \Eqref{overapproximate-lexeme}, \Eqref{overapproximate-nodesize},
                        \eqref{eq:overapproximate-livebit}, \eqref{eq:overapproximate-eolbit}, \Figref{overapproximate}.
        \end{gathered}
\end{equation}
We observe that,
if \VFA{toString}{node} was \texttt{"bbb"},
we would also cache $(\TRUE, \TRUE)$,
but our matches would be false positives.

\FloatBarrier

\section {Example of negative offset}
\label{sec:negoff-example}

{%
\floatstyle{plain}
\restylefloat{figure}
\noindent
\begin{figure}[H]
\vspace{6pt}
% note: default tabcolsep is 6pt
% \rule{30pt}{0pt} needed to trigger use of minimum p cell width
	\begin{tabular}{|c|r|l|}
		\hline
		Range of locations & \multicolumn{1}{|c|}{[TB,ALA]}
			& \multicolumn{1}{|c|}{[ALA,Current]}
			\\
		\hline
            Pre-frame & \multirow{2}{*}{\texttt{"xyz"}} & \\
            token string & & \\
		\hline
		Framed token & & \texttt{"abb"} \\
		\hline
            Lexeme	& & \texttt{/ab*/} \\
		\hline
		Framed lexeme & & \texttt{/abb/} \\
		\hline
\end{tabular}
\vspace{6pt}
\caption{Negative offset example}
\label{fig:negoff}
\end{figure}
} % group for floatstyle

All our examples so far have been positive-offset lexemes.
That is because they present the most difficult cases ---
all unsliceable lexemes are positive-offset lexemes.
Regular expression lexemes with negative offsets
are always sliceable,
because all slices of the lexemes with
negative offsets start at 0,
and the language consisting of the prefixes
of a regular language is always
another regular language.

In this section we look at a negative-offset lexeme
\begin{equation}
    \label{eq:negoff-offset}
        \V{off} = (\V{TB} \subtract \V{ALA}) = {-3} \,\cuz\, \Figref{negoff},
\end{equation}
which is negative.
Our lexeme is
\begin{equation}
        \label{eq:negoff-lexeme}
        \V{lex} = \texttt{/ab*/}. \,\cuz\, \Figref{negoff}.
\end{equation}
\begin{equation}
        \label{eq:negoff-tostring}
        \VFA{toString}{node} = \texttt{"xyzabb"} \cuz \Figref{negoff}.
\end{equation}
\begin{equation}
        \label{eq:negoff-nodesize}
        \Vsize{node} = 6 \cuz \eqref{eq:negoff-tostring}, \Figref{negoff}.
\end{equation}


Applying the formula for framed slices with negative offsets,
\begin{equation}
        \label{eq:negoff-framelex}
\begin{gathered}
\FA{FrameLex}{\V{lex}, \V{off}} \\
	= \Velement{lex}{0, \Vsize{node}+\V{off}} \\
	= \Velement{(\texttt{/ab*/})}{0, 6+(-3)} \\
	= \Velement{(\texttt{/ab*/})}{0, 3} \\
    = \texttt{/abb/} \\
        \cuz \Eqref{negative-framelex}, \eqref{eq:negoff-offset}, \eqref{eq:negoff-lexeme},
                \eqref{eq:negoff-nodesize}, \Figref{negoff}.
\end{gathered}
\end{equation}
Determining the framed token for a negative offset is slightly more
complicated that it has been for the positive offsets.
Applying the formula for overlaps of negative offsets,
\begin{equation}
        \label{eq:negoff-frametok}
        \begin{gathered}
        \FA{FrameTok}{\V{node},\V{off}}
	= \element{(\VFA{toString}{node})}{\Vsize{node}+\V{off}, \Vsize{node}}.\\
	= \element{(\texttt{"xyzabb"})}{6+(-3), 6} \\
	= \element{(\texttt{"xyzabb"})}{3, 6} \\
	= \texttt{"abb"} \\
                \cuz \Eqref{negative-frametok}, \eqref{eq:negoff-offset}, \eqref{eq:negoff-tostring},
                 \eqref{eq:negoff-nodesize}, \Figref{negoff}.
        \end{gathered}
\end{equation}
On the other hand, determining the remaining lexeme is simpler in
the case of a negative offset,
\begin{equation}
        \label{eq:negoff-remlex}
        \begin{gathered}
        \FA{RemLex}{\V{lex}, \V{off}} \\
                = \FA{Rem}{\V{lex}, 0} \\
                        = \V{lex} \\
                    = \texttt{/ab*/} \\
                \cuz \Eqref{negative-remlex}, \eqref{eq:negoff-lexeme}, \Figref{negoff}.
\end{gathered}
\end{equation}

\begin{equation}
        \label{eq:negoff-livebit}
        \begin{gathered}
        \V{LIVE-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{FrameLex}{\V{lex}, \V{off}} \\
                = \texttt{"abb"}  \, \sim \, \texttt{/abb/} \\
                = \TRUE  \\
            \cuz \Eqref{live-bit}, \eqref{eq:negoff-framelex}, \eqref{eq:negoff-frametok}.
        \end{gathered}
\end{equation}
\begin{equation}
        \label{eq:negoff-eolbit}
        \begin{gathered}
        \V{EOL-bit} = \FA{FrameTok}{\V{node},\V{off}} \, \sim \, \FA{RemLex}{\V{lex}, \V{off}} \\
                = \texttt{"abb"} \,\sim\, \texttt{/ab*/} \\
        = \TRUE \\
                \cuz \Eqref{eol-bit}, \eqref{eq:negoff-frametok}, \eqref{eq:negoff-remlex}.
        \end{gathered}
\end{equation}
We can update the cache accordingly:
\begin{equation}
        \begin{gathered}
                \FA{Ruby}{\V{node}, \texttt{/ab*/}, {-3}} \\
                = (\V{LIVE-bit}, \V{EOL-bit}) \\
                = (\TRUE, \TRUE) \\
                \cuz \Eqref{ruby-function}, \Eqref{negoff-lexeme}, \Eqref{negoff-nodesize},
                        \eqref{eq:negoff-livebit}, \eqref{eq:negoff-eolbit}, \Figref{negoff}.
        \end{gathered}
\end{equation}

\FloatBarrier

\section{Afterthoughts}

\subsection{Strings and other long lexemes}
\label{sec:strings}

The optimizations in this document are aimed at inputs
which consist mostly of short lexemes.
This in the case in most programming languages.

There are, however, important exceptions.
It is common for JSON and Lua programs to be essentially
databases,
and to consist in large part,
or almost entirely,
of long lexemes.
Most commonly, long lexemes
are strings of some format,
and for convenience in the rest of this section
we will refer to long lexemes as ``strings''.

To aim dedicated optimizations at strings,
they can be treated as subgrammars.
The subgrammars can be tackled with special techniques
aimed at optimizing that type of string.
Within the sub-grammars these techniques may again
apply.

A Marpa-driven example of string handling in
a complex application is \cite{YAHC},
a Hoon compiler.
Hoon has a wide variety of formats for string-like
objects~\cite{Hoon-strings},
including three lexeme types specifically intended for
long lexemes: strings bounded by triple single quotes,
strings bounded by triple double quotes,
and a "Markdown-esque" sublanguage~\cite{Udon}.

\subsection{Forcing}

The optimization described here detects all situations where there is
only one token-consistent lexeme at a location.
In this way, it can be said to auto-detect all cases of forcing.
This is done as a natural extension of its usual logic for
token-consistent lexemes and their tokenization,
rather than by special-casing.

\subsection{A MEDIAL bit}
\label{sec:medial-bit}

We note that, for presentation purposes,
we use an EOL-bit which is \TRUE if the Ruby triple is at EOL.
In implementation, it may be helpful to replace it with a
MEDIAL-bit, which is \FALSE if the Ruby triple is not at EOL.

The reason this may be desirable is that
when LIVE-bit and EOL-bit are implemented as binary-valued booleans,
only three of the four possible values of the LIVE-bit, EOL-bit duple
are possible:
\begin{itemize}
        \item (\TRUE, \TRUE);
        \item (\TRUE, \FALSE); and
        \item (\FALSE, \FALSE).
\end{itemize}
The $(\FALSE, \TRUE)$ duple value in this case is ``wasted''.

Instead of wasting
the $(\FALSE, \TRUE)$ value of the duple,
it can be treated as an ``uncomputed'' value.
That is,
a $(\FALSE, \TRUE)$ duple can be taken to mean
that the LIVE-bit and EOL-bit values in the cache
have yet to be computed.

In this case, it a MEDIAL-bit is used instead of an EOL-bit, the
``uncomputed'' value will be
\[ (\FALSE, \FALSE). \]
If the caching uses, for example, a bit vector with all bits initialized to
\FALSE then, by default, a new bit vector will be initialized to ``uncomputed''
values, which can be convenient.

{
\clearpage

% Ragged right, do not hyphenate.
\RaggedRight
\hyphenpenalty=10000
\exhyphenpenalty=10000

% Silence current hbox warnings, but allow them if
% badness increases further
\hbadness=2000

\begin{thebibliography}{10}

\bibitem{Kegler2011a}
\newblock{Jeffrey Kegler.}
\newblock{``What is the Marpa algorithm?''.}
\newblock{\url{https://blogs.perl.org/users/jeffrey_kegler/2011/11/what-is-the-marpa-algorithm.html}.
   Retrieved 2 December, 2024.}

\bibitem{Kegler2011b}
\newblock{Jeffrey Kegler.}
\newblock{``Marpa and the Ruby Slippers''.}
\newblock{\url{http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2011/11/marpa-and-the-ruby-slippers.html}.
   Retrieved 2 December, 2024.}

\bibitem{Kegler2023}
\newblock{Jeffrey Kegler.}
\newblock{``Marpa, A practical general parser: the recognizer''.}
\newblock{\url{https://arxiv.org/abs/1910.08129}.
   Retrieved 2 December, 2024.}

\bibitem{YAHC}
\newblock{Jeffrey Kegler.}
\newblock{``Yet Another Hoon Compiler''.}
\newblock{\url{https://github.com/jeffreykegler/yahc}.
        Retrieved 1 February 2025.}

\bibitem{llguidance}
\newblock{llguidance team.}
\newblock{"Low-level guidance parser".}
\newblock{
  \url{https://github.com/microsoft/llguidance}.
  Retrieved 2 December, 2024.}

\bibitem{Hoon-strings}
\newblock{Urbit.org authors.}
\newblock{``Strings - Language - docs.urbit.org''}
\newblock{\url{https://docs.urbit.org/language/hoon/guides/strings}.
        Retrieved 1 February 2025.}

\bibitem{Udon}
\newblock{Urbit.org authors.}
\newblock{``Udon (Markdown-esque) - Language - docs.urbit.org''.}
\newblock{\url{https://docs.urbit.org/language/hoon/guides/udon}.
        Retrieved 1 February 2025.}

\bibitem{wiki-loop-invariant}
\newblock{Wikipedia contributors.}
\newblock{"Loop-invariant code motion --- {Wikipedia}{,} The Free Encyclopedia".}
\newblock{\url{https://en.wikipedia.org/w/index.php?title=Loop-invariant_code_motion&oldid=1249559170}.
	Retrieved 16 December 2024.}

\bibitem{XGrammar2024}
\newblock{Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao and Tianqi Chen.}
\newblock{``XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models''.}
\newblock{\url{https://arxiv.org/abs/2411.15100}.
	Retrieved 16 December 2024.}

\end{thebibliography}

} % RaggedRight

\clearpage
\tableofcontents

% \clearpage
% \phantomsection
% \listofalgorithms

\ifdraft{
    \clearpage
    \phantomsection
    \listoftodos
}{}



\end{document}
